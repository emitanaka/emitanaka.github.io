{
  "hash": "d3444bc939eef4446ea9806e6800318a",
  "result": {
    "markdown": "---\ntitle: \"Getting the most out of your experimental data with design\"\ndescription: \"The content of this blog post is originally published in the Biometric Bulletin (2022) Volume 39 Issue 4.\"\nauthor: Emi Tanaka\ninstitute: Monash University\ndate: \"12/12/2022\"\ndraft: false\nbibliography: ref.bib\n#output-file: index.html\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Introduction\n\nExperimental data are hallmarks of proving or disproving theories or hypotheses. Not all experimental data are of equal value however; the design of experiment and the execution to collect data greatly shape its downstream value. The seminal book by @Fisher1935-qc outline the importance of randomisation, replication and (statistical) control in experimental designs motivated primary by agricultural field trials. @Fisher1935-qc also introduce special cases of row-column designs, such as Latin Square and Graeco-Latin Square designs, factorial designs and the analysis of experimental data using analysis of variance (ANOVA), $t$-test, $\\chi^2$-test and other tests of significance. @Montgomery2001-gh, @Box2005-yj, and @Hinkelmann2005-jq are classical textbooks in experimental designs taught in many courses in experimental design. Many of these textbooks, and the teaching of experimental designs, I would argue is focussed on statistical aspects, but in practice, the primary problem in carrying out an experiment is actually centered on human aspects. Consider the following simplified scenario:\n\n- the **domain expert** wants an experiment to validate their hypothesis and needs a statistician to design the experiment;\n- the **statistician** elicits the experimental aim and structure from the domain expert and then design the experiment accounting appropriately for statistical issues and practical constraints; \n- the **technician** carries out the experimental protocol as directed by the experimental design generated by the statistician and enter the data; and then\n- the **analyst** (who may or may not be the same person as the statistician) interprets the experimental aim and design to appropriately analyse the data.\n\nHow many people were involved in this experiment? Notice that we are reliant on  communication between people, who likely have different discipline backgrounds, to transfer the correct information in order to successfully carry out the experiment. We know human communication is fraught with challenges; **_misunderstandings are common, not the exception_**. The unwritten assumption in experimental designs is that all parties involved in the experiment completely understood each other -- the statistician understood all the intricacies that the domain expert knows that may affect the experimental outcome, and the technician will carry out the experiment exactly as the design of experiment with no possible error. This assumption is in contrary to what we know about human communication; human communication is a noisy process. What then can we do to mitigate errors in the process?\n\n\n## The grammar of experimental designs\n\nThe so-called \"The Grammar of Experimental Designs\" is the title of my work-in-progress book found at [emitanaka.org/edibble-book](https://emitanaka.org/edibble-book). More details can be found in the book, but briefly, the **grammar of experimental designs** is an object oriented programming system designed to capture elements of the origin of an experimental data encapsulated in a cognitive framework. It is an attempt to standardise the computational description of experimental components by fundamental terms so we are not lost in domain-specific jargon. \n\nThe motivation of the grammar of experimental designs is best explained by an analogy to the \"grammar of graphics\" [@Wilkinson2005-oz] with its most popular implementation as ggplot2 [@Wickham2016-yg] in the R language [@Rstats]. When we specify a plot, we can specify using a complete recipe. For example, the functions `barplot()` and `pie()` create a barplot and a pie chart, respectively, in the base R language -- these functions are for a single purpose, nothing more.\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\ndata <- data.frame(duty = c(\"teaching\", \"research\", \"admin\"),\n                   percentage = c(40, 40, 20))\n\nbarplot(data$percentage, names.arg = data$duty)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-base-1.png){width=672}\n:::\n\n```{.r .cell-code}\npie(data$percentage, labels = data$duty)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-base-2.png){width=672}\n:::\n:::\n\nWhen we specify plots using ggplot2, the system requires users to _specify components of the plot_, not the full plot. This not only gives greater control over the construction of the plot but it encourages the user to think about the relationship between data to plot elements. For example, below we create the pie chart and barplot using ggplot2. The first specification in ggplot2 is to initiate the object by `ggplot()` where the user can specify the data and the mapping of variable to plot aesthetic, then the user can append a layer like `geom_col()` to create a barplot. To construct a pie chart in ggplot2, the user must transform the default Cartesian coordinate system to a polar coordinate along one of the axis.\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n# bar plot\nggplot(data, aes(x = duty, y = percentage)) +\n  geom_col() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-ggplot2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# pie chart\nggplot(data, aes(x = \"\", y = percentage, fill = duty)) +\n  geom_col() + \n  coord_polar(\"y\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-ggplot2-2.png){width=672}\n:::\n:::\n\nThe ggplot2 system has a steep learning curve, however, the mastery of the system allows users to easily create a variety of plots. In a similar vein, the grammar of experimental designs is a system to construct experimental designs by experimental components -- the users don't need to specify the complete design but build up the experimental design by its basic components, like experimental units and treatments, giving them the flexibility in their thinking and specifciation of the experimental structure. The easiest way to grasp the grammar of experimental design is to see examples of its implementation as shown next.\n\n## Constructing experimental designs with the **edibble** R package\n\nThe edibble package is a system in the R language to facilitate the design of comparative experiments based on the grammar of experimental designs. The package is available on Comprehensive R Arhive Network (CRAN) with the developmental version available at [github.com/emitanaka/edibble](https://github.com/emitanaka/edibble) and can be installed as below.\n::: {.cell}\n\n```{.r .cell-code}\n# installing from CRAN\ninstall.packages(\"edibble\") \n# OR for the developmental version\ninstall.packages(\"remotes\") \nremotes::install_github(\"emitanaka/edibble\") \n```\n:::\n\n### Package name\n\nThe name of the package, edibble, stands for the **e**xperimental **d**esign table or t**ibble** for those that are familiar with tidyverse [@Wickham2019-mj]. I often see people misspell it as eddible or edible (latter probably due to autocorrect), so I want to emphasise that is is edibble, i.e. one d and two b. \n\nThe package name itself relates to the aim of what it tries to produce, i.e. a table where columns specifies the unit and treatment factors in the experimental design and rows specify the characteristics of the observational unit, including the allocated treatment. \n\n### Example usage\n\nLet's suppose that we want to create a randomised complete block design (RCBD) with 6 blocks with 3 plots in each block to test 3 wheat varieties, labelled A, B and C. As not all of you may know what a RCBD is, to describe it more explicitly, the treatments (in this case the 3 wheat varieties) are randomly allocated to one of the plot (experimental unit) within a block; only one treatment level can be assigned to each plot; and each treatment level must appear exactly once in each block. The specification of this design in the edibble system is shown below and can be interpreted as follows:\n\n- Line 1: load the library,\n- Line 2: set the seed to ensure replication of the randomised design,\n- Line 3: initialise the design object,\n- Line 4-5: set the unit factors, namely 6 blocks and 3 plots nested in each block,\n- Line 6: set the treatment factor, variety, with 3 levels (A, B, and C),\n- Line 7: specify the high-level treatment to unit allocation,\n- Line 8: assign the treatment randomly, and\n- Line 9: the design specification is complete, now convert the result to a table.\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nlibrary(edibble)\nset.seed(2022) \ndesign(\"Randomised Complete Block Design\") %>% \n  set_units(block = 6,\n            plot = nested_in(block, 3)) %>% \n  set_trts(variety = c(\"A\", \"B\", \"C\")) %>% \n  allot_trts(variety ~ plot) %>% \n  assign_trts(\"random\") %>% \n  serve_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Randomised Complete Block Design \n# An edibble: 18 x 3\n       block       plot  variety\n   <unit(6)> <unit(18)> <trt(3)>\n 1    block1     plot1         A\n 2    block1     plot2         B\n 3    block1     plot3         C\n 4    block2     plot4         A\n 5    block2     plot5         B\n 6    block2     plot6         C\n 7    block3     plot7         A\n 8    block3     plot8         C\n 9    block3     plot9         B\n10    block4     plot10        C\n11    block4     plot11        B\n12    block4     plot12        A\n13    block5     plot13        B\n14    block5     plot14        C\n15    block5     plot15        A\n16    block6     plot16        C\n17    block6     plot17        B\n18    block6     plot18        A\n```\n:::\n:::\n\nAbove table output shows the resulting allocation of the treatment to units, e.g. from the first row we see that first plot in the first block is assigned variety A. \n\nNow consider the design specified below. How is this different to above?\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\ndesign(\"Do exam type matter?\") %>% \n  set_units(school = 6,\n            student = nested_in(school, 3)) %>% \n  set_trts(exam = c(\"Oral\", \"Written\", \"Computer\")) %>% \n  allot_trts(exam ~ school) %>% \n  assign_trts(\"random\") %>% \n  serve_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Do exam type matter? \n# An edibble: 18 x 3\n      school    student     exam\n   <unit(6)> <unit(18)> <trt(3)>\n 1   school1  student1  Oral    \n 2   school1  student2  Oral    \n 3   school1  student3  Oral    \n 4   school2  student4  Computer\n 5   school2  student5  Computer\n 6   school2  student6  Computer\n 7   school3  student7  Oral    \n 8   school3  student8  Oral    \n 9   school3  student9  Oral    \n10   school4  student10 Written \n11   school4  student11 Written \n12   school4  student12 Written \n13   school5  student13 Computer\n14   school5  student14 Computer\n15   school5  student15 Computer\n16   school6  student16 Written \n17   school6  student17 Written \n18   school6  student18 Written \n```\n:::\n:::\n\nFirst, you may have noticed that the experimental factors are named differently. The names that you enter in `set_units()` and `set_trts()` are not fixed by the system -- the user may enter the name that is appropriate for their experimental context. These are just simply labels but it captures the valuable experimental context. In fact, the unit structure is exactly the same as the previous experiment! But it's easy to see that the first experiment is a wheat variety trial but the second experiment is comparing the exam type across schools. \n\nSecond, aside from labels, you may have noticed everything is the same as the previous experiment except line 5. The treatment (exam type) are randomly allocated to schools, not individual students within a school. You can see this in the resulting table output -- each school gets only one type of exam. The resulting design is in fact called a completely randomised design. Here, the experimental units are the schools and the intended observational units are the students.  \n\nYou may think the edibble system is only for balanced designs (where there is equal number of units within a block), but you can easily specify unbalanced designs as shown in line 3-5 below where there are two blocks (labelled I and II) where block I has 3 plots and block II has 6 plots.\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\ndesign(\"Unbalanced design\") %>% \n  set_units(block = c(\"I\", \"II\"),\n            plot = nested_in(block, \n                              \"I\" ~ 3,\n                             \"II\" ~ 6)) %>% \n  set_trts(variety = c(\"A\", \"B\", \"C\")) %>% \n  allot_trts(variety ~ plot) %>% \n  assign_trts(\"random\") %>% \n  serve_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Unbalanced design \n# An edibble: 9 x 3\n      block      plot  variety\n  <unit(2)> <unit(9)> <trt(3)>\n1        I      plot1        B\n2        I      plot2        A\n3        I      plot3        C\n4        II     plot4        C\n5        II     plot5        A\n6        II     plot6        B\n7        II     plot7        C\n8        II     plot8        B\n9        II     plot9        A\n```\n:::\n:::\n\nThere are more features in the edibble system. These features include setting responses using `set_rcrds()`, simulating responses with `simulate_rcrds()` (experimental only), and setting expectation of responses `expect_rcrds()`, e.g. when values should be positive numbers only. The latter allows files to be encoded with data validation rules, e.g. `export_design()` outputs the edibble table as an Excel file where values outside of expectation cannot be entered by exploiting Excel's data validation system. \n\nThe edibble system has been designed so that developers can extend the system. If the `assign_trts()` is not suitable, then you can replace this with an alternative one. Likewise, if an Excel output is not desired then you can replace the exporting system with another system. The system exposes its components as modular functions to allow extensibility. The caveat of the edibble system is that there is a steep learning curve for both the user and the developer -- but mastery of the grammar should help you flexibly specify a variety of experimental designs and deepen your thinking about the experimental design. \n\n## Recipe experimental designs\n\n> \"Good design considers units and treatments first, and then allocates treatments to units. It does not choose from a menu of named designs.\"\n> -- @Bailey2008-gw\n\nI highly discourage the use of named experimental designs, but I acknowledge that the literature is littered with them. The compromise I have made is to include a set of functions that are prefixed with `menu_`. For example, below `menu_rcbd()` shows the code to generate a RCBD with 3 treatments and 6 blocks. If you must take this approach, I suggest that you copy the output code and replace the generic factor names with what is appropriate in the context of your own experiment. \n\n::: {.cell}\n\n```{.r .cell-code}\nmenu_rcbd(t = 3, r = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndesign(\"Randomised Complete Block Design\") %>%\n  set_units(block = 6,\n            unit = nested_in(block, 3)) %>%\n  set_trts(trt = 3) %>%\n  allot_trts(trt ~ unit) %>%\n  assign_trts(\"random\", seed = 424) %>%\n  serve_table()\n```\n:::\n:::\n\nIf you want to actually see a table output then you can `takeout()` any named design (on the menu). Say below `menu_lsd()` shows the code for generating a Latin Square design; the `takeout()` of this design on the menu shows the table output of the Latin Square design with 4 treatments. \n\n::: {.cell}\n\n```{.r .cell-code}\ntakeout(menu_lsd(t = 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndesign(\"Latin Square Design\") %>%\n  set_units(row = 4,\n            col = 4,\n            unit = crossed_by(row, col)) %>%\n  set_trts(trt = 4) %>%\n  allot_trts(trt ~ unit) %>%\n  assign_trts(\"random\", seed = 794) %>%\n  serve_table() \n\n# Latin Square Design \n# An edibble: 16 x 4\n         row       col       unit      trt\n * <unit(4)> <unit(4)> <unit(16)> <trt(4)>\n 1      row1      col1     unit1      trt1\n 2      row2      col1     unit2      trt3\n 3      row3      col1     unit3      trt4\n 4      row4      col1     unit4      trt2\n 5      row1      col2     unit5      trt4\n 6      row2      col2     unit6      trt2\n 7      row3      col2     unit7      trt1\n 8      row4      col2     unit8      trt3\n 9      row1      col3     unit9      trt3\n10      row2      col3     unit10     trt4\n11      row3      col3     unit11     trt2\n12      row4      col3     unit12     trt1\n13      row1      col4     unit13     trt2\n14      row2      col4     unit14     trt1\n15      row3      col4     unit15     trt3\n16      row4      col4     unit16     trt4\n```\n:::\n:::\n\nThe full list of available named experimental designs can be found in the [Cookbook chapter in The Grammar of Experimental Designs book](https://emitanaka.org/edibble-book/cookbook.html).\n\n\n## Conclusion\n\nThe design of an experiment is, without a doubt, of critical importance in the advancement of our knowledge. In fact, a good experimental design and well executed collection of data can eliminate or reduce the necessity of certain statistical analysis. The use of experimental designs in practice are arguably propagated by statistical software and interested readers can see @tanaka2022 for a review of popular R packages in experimental design. The edibble R package is an attempt to specify designs by a paradigm that is flexible, yet human-centered. By building designs based on its components, users are required to think about the ingredients that make up the composition of the experimental structure -- this system design I would hope translates to higher order thinking about experimental designs.\n\nThis article did not touch on much about optimal, adaptive, model-based nor domain-specific designs. The scope of work in the design of experiments is large and substantial work remain to bridge the gap between the principles and practice of experimental designs. Too often, teaching of experimental design is overshadowed by the analysis of experimental data and to get the most out of experimental data, we should remember that experimental context is invaluable in the design and no analysis can extract information from rubbish data.\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}