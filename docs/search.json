[
  {
    "objectID": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html",
    "href": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html",
    "title": "Getting the most out of your experimental data with design",
    "section": "",
    "text": "Experimental data are hallmarks of proving or disproving theories or hypotheses. Not all experimental data are of equal value however; the design of experiment and the execution to collect data greatly shape its downstream value. The seminal book by Fisher (1935) outline the importance of randomisation, replication and (statistical) control in experimental designs motivated primary by agricultural field trials. Fisher (1935) also introduce special cases of row-column designs, such as Latin Square and Graeco-Latin Square designs, factorial designs and the analysis of experimental data using analysis of variance (ANOVA), \\(t\\)-test, \\(\\chi^2\\)-test and other tests of significance. Montgomery (2001), Box, Stuart Hunter, and Hunter (2005), and Hinkelmann and Kempthorne (2005) are classical textbooks in experimental designs taught in many courses in experimental design. Many of these textbooks, and the teaching of experimental designs, I would argue is focussed on statistical aspects, but in practice, the primary problem in carrying out an experiment is actually centered on human aspects. Consider the following simplified scenario:\n\nthe domain expert wants an experiment to validate their hypothesis and needs a statistician to design the experiment;\nthe statistician elicits the experimental aim and structure from the domain expert and then design the experiment accounting appropriately for statistical issues and practical constraints;\nthe technician carries out the experimental protocol as directed by the experimental design generated by the statistician and enter the data; and then\nthe analyst (who may or may not be the same person as the statistician) interprets the experimental aim and design to appropriately analyse the data.\n\nHow many people were involved in this experiment? Notice that we are reliant on communication between people, who likely have different discipline backgrounds, to transfer the correct information in order to successfully carry out the experiment. We know human communication is fraught with challenges; misunderstandings are common, not the exception. The unwritten assumption in experimental designs is that all parties involved in the experiment completely understood each other – the statistician understood all the intricacies that the domain expert knows that may affect the experimental outcome, and the technician will carry out the experiment exactly as the design of experiment with no possible error. This assumption is in contrary to what we know about human communication; human communication is a noisy process. What then can we do to mitigate errors in the process?"
  },
  {
    "objectID": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#the-grammar-of-experimental-designs",
    "href": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#the-grammar-of-experimental-designs",
    "title": "Getting the most out of your experimental data with design",
    "section": "The grammar of experimental designs",
    "text": "The grammar of experimental designs\nThe so-called “The Grammar of Experimental Designs” is the title of my work-in-progress book found at emitanaka.org/edibble-book. More details can be found in the book, but briefly, the grammar of experimental designs is an object oriented programming system designed to capture elements of the origin of an experimental data encapsulated in a cognitive framework. It is an attempt to standardise the computational description of experimental components by fundamental terms so we are not lost in domain-specific jargon.\nThe motivation of the grammar of experimental designs is best explained by an analogy to the “grammar of graphics” (Wilkinson 2005) with its most popular implementation as ggplot2 (Wickham 2016) in the R language (R Core Team 2021). When we specify a plot, we can specify using a complete recipe. For example, the functions barplot() and pie() create a barplot and a pie chart, respectively, in the base R language – these functions are for a single purpose, nothing more.\n\ndata <- data.frame(duty = c(\"teaching\", \"research\", \"admin\"),\n                   percentage = c(40, 40, 20))\n\nbarplot(data$percentage, names.arg = data$duty)\npie(data$percentage, labels = data$duty)\n\n\n\n\n\n\n\n\n\n\n\nWhen we specify plots using ggplot2, the system requires users to specify components of the plot, not the full plot. This not only gives greater control over the construction of the plot but it encourages the user to think about the relationship between data to plot elements. For example, below we create the pie chart and barplot using ggplot2. The first specification in ggplot2 is to initiate the object by ggplot() where the user can specify the data and the mapping of variable to plot aesthetic, then the user can append a layer like geom_col() to create a barplot. To construct a pie chart in ggplot2, the user must transform the default Cartesian coordinate system to a polar coordinate along one of the axis.\n\nlibrary(ggplot2)\n# bar plot\nggplot(data, aes(x = duty, y = percentage)) +\n  geom_col() \n# pie chart\nggplot(data, aes(x = \"\", y = percentage, fill = duty)) +\n  geom_col() + \n  coord_polar(\"y\")\n\n\n\n\n\n\n\n\n\n\n\nThe ggplot2 system has a steep learning curve, however, the mastery of the system allows users to easily create a variety of plots. In a similar vein, the grammar of experimental designs is a system to construct experimental designs by experimental components – the users don’t need to specify the complete design but build up the experimental design by its basic components, like experimental units and treatments, giving them the flexibility in their thinking and specifciation of the experimental structure. The easiest way to grasp the grammar of experimental design is to see examples of its implementation as shown next."
  },
  {
    "objectID": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#constructing-experimental-designs-with-the-edibble-r-package",
    "href": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#constructing-experimental-designs-with-the-edibble-r-package",
    "title": "Getting the most out of your experimental data with design",
    "section": "Constructing experimental designs with the edibble R package",
    "text": "Constructing experimental designs with the edibble R package\nThe edibble package is a system in the R language to facilitate the design of comparative experiments based on the grammar of experimental designs. The package is available on Comprehensive R Arhive Network (CRAN) with the developmental version available at github.com/emitanaka/edibble and can be installed as below. ::: {.cell}\n# installing from CRAN\ninstall.packages(\"edibble\") \n# OR for the developmental version\ninstall.packages(\"remotes\") \nremotes::install_github(\"emitanaka/edibble\") \n:::\n\nPackage name\nThe name of the package, edibble, stands for the experimental design table or tibble for those that are familiar with tidyverse (Wickham et al. 2019). I often see people misspell it as eddible or edible (latter probably due to autocorrect), so I want to emphasise that is is edibble, i.e. one d and two b.\nThe package name itself relates to the aim of what it tries to produce, i.e. a table where columns specifies the unit and treatment factors in the experimental design and rows specify the characteristics of the observational unit, including the allocated treatment.\n\n\nExample usage\nLet’s suppose that we want to create a randomised complete block design (RCBD) with 6 blocks with 3 plots in each block to test 3 wheat varieties, labelled A, B and C. As not all of you may know what a RCBD is, to describe it more explicitly, the treatments (in this case the 3 wheat varieties) are randomly allocated to one of the plot (experimental unit) within a block; only one treatment level can be assigned to each plot; and each treatment level must appear exactly once in each block. The specification of this design in the edibble system is shown below and can be interpreted as follows:\n\nLine 1: load the library,\nLine 2: set the seed to ensure replication of the randomised design,\nLine 3: initialise the design object,\nLine 4-5: set the unit factors, namely 6 blocks and 3 plots nested in each block,\nLine 6: set the treatment factor, variety, with 3 levels (A, B, and C),\nLine 7: specify the high-level treatment to unit allocation,\nLine 8: assign the treatment randomly, and\nLine 9: the design specification is complete, now convert the result to a table.\n\n\nlibrary(edibble)\nset.seed(2022) \ndesign(\"Randomised Complete Block Design\") %>% \n  set_units(block = 6,\n            plot = nested_in(block, 3)) %>% \n  set_trts(variety = c(\"A\", \"B\", \"C\")) %>% \n  allot_trts(variety ~ plot) %>% \n  assign_trts(\"random\") %>% \n  serve_table()\n\n# Randomised Complete Block Design \n# An edibble: 18 x 3\n       block       plot  variety\n   <unit(6)> <unit(18)> <trt(3)>\n 1    block1     plot1         A\n 2    block1     plot2         B\n 3    block1     plot3         C\n 4    block2     plot4         A\n 5    block2     plot5         B\n 6    block2     plot6         C\n 7    block3     plot7         A\n 8    block3     plot8         C\n 9    block3     plot9         B\n10    block4     plot10        C\n11    block4     plot11        B\n12    block4     plot12        A\n13    block5     plot13        B\n14    block5     plot14        C\n15    block5     plot15        A\n16    block6     plot16        C\n17    block6     plot17        B\n18    block6     plot18        A\n\n\nAbove table output shows the resulting allocation of the treatment to units, e.g. from the first row we see that first plot in the first block is assigned variety A.\nNow consider the design specified below. How is this different to above?\n\ndesign(\"Do exam type matter?\") %>% \n  set_units(school = 6,\n            student = nested_in(school, 3)) %>% \n  set_trts(exam = c(\"Oral\", \"Written\", \"Computer\")) %>% \n  allot_trts(exam ~ school) %>% \n  assign_trts(\"random\") %>% \n  serve_table()\n\n# Do exam type matter? \n# An edibble: 18 x 3\n      school    student     exam\n   <unit(6)> <unit(18)> <trt(3)>\n 1   school1  student1  Oral    \n 2   school1  student2  Oral    \n 3   school1  student3  Oral    \n 4   school2  student4  Computer\n 5   school2  student5  Computer\n 6   school2  student6  Computer\n 7   school3  student7  Oral    \n 8   school3  student8  Oral    \n 9   school3  student9  Oral    \n10   school4  student10 Written \n11   school4  student11 Written \n12   school4  student12 Written \n13   school5  student13 Computer\n14   school5  student14 Computer\n15   school5  student15 Computer\n16   school6  student16 Written \n17   school6  student17 Written \n18   school6  student18 Written \n\n\nFirst, you may have noticed that the experimental factors are named differently. The names that you enter in set_units() and set_trts() are not fixed by the system – the user may enter the name that is appropriate for their experimental context. These are just simply labels but it captures the valuable experimental context. In fact, the unit structure is exactly the same as the previous experiment! But it’s easy to see that the first experiment is a wheat variety trial but the second experiment is comparing the exam type across schools.\nSecond, aside from labels, you may have noticed everything is the same as the previous experiment except line 5. The treatment (exam type) are randomly allocated to schools, not individual students within a school. You can see this in the resulting table output – each school gets only one type of exam. The resulting design is in fact called a completely randomised design. Here, the experimental units are the schools and the intended observational units are the students.\nYou may think the edibble system is only for balanced designs (where there is equal number of units within a block), but you can easily specify unbalanced designs as shown in line 3-5 below where there are two blocks (labelled I and II) where block I has 3 plots and block II has 6 plots.\n\ndesign(\"Unbalanced design\") %>% \n  set_units(block = c(\"I\", \"II\"),\n            plot = nested_in(block, \n                              \"I\" ~ 3,\n                             \"II\" ~ 6)) %>% \n  set_trts(variety = c(\"A\", \"B\", \"C\")) %>% \n  allot_trts(variety ~ plot) %>% \n  assign_trts(\"random\") %>% \n  serve_table()\n\n# Unbalanced design \n# An edibble: 9 x 3\n      block      plot  variety\n  <unit(2)> <unit(9)> <trt(3)>\n1        I      plot1        B\n2        I      plot2        A\n3        I      plot3        C\n4        II     plot4        C\n5        II     plot5        A\n6        II     plot6        B\n7        II     plot7        C\n8        II     plot8        B\n9        II     plot9        A\n\n\nThere are more features in the edibble system. These features include setting responses using set_rcrds(), simulating responses with simulate_rcrds() (experimental only), and setting expectation of responses expect_rcrds(), e.g. when values should be positive numbers only. The latter allows files to be encoded with data validation rules, e.g. export_design() outputs the edibble table as an Excel file where values outside of expectation cannot be entered by exploiting Excel’s data validation system.\nThe edibble system has been designed so that developers can extend the system. If the assign_trts() is not suitable, then you can replace this with an alternative one. Likewise, if an Excel output is not desired then you can replace the exporting system with another system. The system exposes its components as modular functions to allow extensibility. The caveat of the edibble system is that there is a steep learning curve for both the user and the developer – but mastery of the grammar should help you flexibly specify a variety of experimental designs and deepen your thinking about the experimental design."
  },
  {
    "objectID": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#recipe-experimental-designs",
    "href": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#recipe-experimental-designs",
    "title": "Getting the most out of your experimental data with design",
    "section": "Recipe experimental designs",
    "text": "Recipe experimental designs\n\n“Good design considers units and treatments first, and then allocates treatments to units. It does not choose from a menu of named designs.” – Bailey (2008)\n\nI highly discourage the use of named experimental designs, but I acknowledge that the literature is littered with them. The compromise I have made is to include a set of functions that are prefixed with menu_. For example, below menu_rcbd() shows the code to generate a RCBD with 3 treatments and 6 blocks. If you must take this approach, I suggest that you copy the output code and replace the generic factor names with what is appropriate in the context of your own experiment.\n\nmenu_rcbd(t = 3, r = 6)\n\ndesign(\"Randomised Complete Block Design\") %>%\n  set_units(block = 6,\n            unit = nested_in(block, 3)) %>%\n  set_trts(trt = 3) %>%\n  allot_trts(trt ~ unit) %>%\n  assign_trts(\"random\", seed = 424) %>%\n  serve_table()\n\n\nIf you want to actually see a table output then you can takeout() any named design (on the menu). Say below menu_lsd() shows the code for generating a Latin Square design; the takeout() of this design on the menu shows the table output of the Latin Square design with 4 treatments.\n\ntakeout(menu_lsd(t = 4))\n\ndesign(\"Latin Square Design\") %>%\n  set_units(row = 4,\n            col = 4,\n            unit = crossed_by(row, col)) %>%\n  set_trts(trt = 4) %>%\n  allot_trts(trt ~ unit) %>%\n  assign_trts(\"random\", seed = 794) %>%\n  serve_table() \n\n# Latin Square Design \n# An edibble: 16 x 4\n         row       col       unit      trt\n * <unit(4)> <unit(4)> <unit(16)> <trt(4)>\n 1      row1      col1     unit1      trt1\n 2      row2      col1     unit2      trt3\n 3      row3      col1     unit3      trt4\n 4      row4      col1     unit4      trt2\n 5      row1      col2     unit5      trt4\n 6      row2      col2     unit6      trt2\n 7      row3      col2     unit7      trt1\n 8      row4      col2     unit8      trt3\n 9      row1      col3     unit9      trt3\n10      row2      col3     unit10     trt4\n11      row3      col3     unit11     trt2\n12      row4      col3     unit12     trt1\n13      row1      col4     unit13     trt2\n14      row2      col4     unit14     trt1\n15      row3      col4     unit15     trt3\n16      row4      col4     unit16     trt4\n\n\nThe full list of available named experimental designs can be found in the Cookbook chapter in The Grammar of Experimental Designs book."
  },
  {
    "objectID": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#conclusion",
    "href": "blog/2022-10-23-edibble-for-biometrics-bulletin/index.html#conclusion",
    "title": "Getting the most out of your experimental data with design",
    "section": "Conclusion",
    "text": "Conclusion\nThe design of an experiment is, without a doubt, of critical importance in the advancement of our knowledge. In fact, a good experimental design and well executed collection of data can eliminate or reduce the necessity of certain statistical analysis. The use of experimental designs in practice are arguably propagated by statistical software and interested readers can see Tanaka and Amaliah (2022) for a review of popular R packages in experimental design. The edibble R package is an attempt to specify designs by a paradigm that is flexible, yet human-centered. By building designs based on its components, users are required to think about the ingredients that make up the composition of the experimental structure – this system design I would hope translates to higher order thinking about experimental designs.\nThis article did not touch on much about optimal, adaptive, model-based nor domain-specific designs. The scope of work in the design of experiments is large and substantial work remain to bridge the gap between the principles and practice of experimental designs. Too often, teaching of experimental design is overshadowed by the analysis of experimental data and to get the most out of experimental data, we should remember that experimental context is invaluable in the design and no analysis can extract information from rubbish data."
  },
  {
    "objectID": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html",
    "href": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html",
    "title": "Manipulating arrays with dynamic dimensions in R",
    "section": "",
    "text": "Below I am creating an array of dimensions \\(3 \\times 2 \\times 4\\) with each entry containing a unique value.\n\nx <- array(1:24, dim = c(3, 2, 4))\nx\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   13   16\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   19   22\n[2,]   20   23\n[3,]   21   24\n\nclass(x)\n\n[1] \"array\"\n\n\nYou can access the entry \\((1, 1, 1)\\), i.e. the cell value in first entries of each dimension, in R by:\n\nx[1, 1, 1]\n\n[1] 1\n\n\nIf you want the entries \\((i, 1, 1)\\) where \\(i = 1, 2, 3\\) then you can leave the first element blank in R like below:\n\nx[, 1, 1]\n\n[1] 1 2 3\n\n\nIn the above code, the result is a vector but if you wanted to keep the array structure as is then you could add drop = FALSE like below:\n\nx[, 1, 1, drop = FALSE]\n\n, , 1\n\n     [,1]\n[1,]    1\n[2,]    2\n[3,]    3\n\n\nIf you want the entries \\((1, j, k)\\) where \\(j = 1, 2\\) and \\(k = 1, 2, 3, 4\\), then you can leave the first two entries in the square bracket like below:\n\nx[1, , ]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    7   13   19\n[2,]    4   10   16   22\n\n\nThe above result isn’t actually a vector but a two dimensional array, or more specifically it has the classes matrix and array.\n\nclass(x[1, , ])\n\n[1] \"matrix\" \"array\" \n\n\nI can modify elements in an array by using the assignment operator (<- or =) like below:\n\nx3 <- x2 <- x\nx2[1, , ] <- NA\nx2\n\n, , 1\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]   20   23\n[3,]   21   24\n\nx3[1, , ] <- array(1:8, dim = c(2, 4))\nx3\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    3    4\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]    5    6\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]    7    8\n[2,]   20   23\n[3,]   21   24"
  },
  {
    "objectID": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#the-challenge",
    "href": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#the-challenge",
    "title": "Manipulating arrays with dynamic dimensions in R",
    "section": "The challenge",
    "text": "The challenge\n\nChallenge 1: indexing\nUp to this point, it’s pretty straight forward. But let’s say now we create a function that returns the first element of the first dimension.\n\nindex_first <- function(x) {\n  x[1, , ]\n}\n\nindex_first(x)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    7   13   19\n[2,]    4   10   16   22\n\ny <- array(1, dim = c(2, 4, 2))\nindex_first(y)\n\n     [,1] [,2]\n[1,]    1    1\n[2,]    1    1\n[3,]    1    1\n[4,]    1    1\n\n\nThe above function works fine for the arrays x and y. But what if the number of dimension is different?\n\nz <- array(dim = c(2, 2, 2, 2))\nindex_first(z)\n\nError in x[1, , ]: incorrect number of dimensions\n\n\nSo how do we change our function so it works for an array of any number of dimensions? This is where it gets quite challenging. And while I’m at it, let me throw another challenge.\n\n\nChallenge 2: assignment\nSuppose now I want a function that modifies the entries in the first element of the first dimension by a user supplied value.\n\nmodify_first <- function(x, value) {\n  x[1, ,] <- value\n}\n\n\nmodify_first(x, NA)\nmodify_first(x, array(1:8, dim = c(2, 4)))\n\nAgain this works fine until we have an array with different number of dimensions.\n\nmodify_first(z, 1)\n\nError in x[1, , ] <- value: incorrect number of subscripts\n\n\nSo how would you modify the function so this can be generalised for arrays with a different number of dimensions?"
  },
  {
    "objectID": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#solutions",
    "href": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#solutions",
    "title": "Manipulating arrays with dynamic dimensions in R",
    "section": "Solutions",
    "text": "Solutions\nIn the first instance, it’s useful to know that the square brackets are in fact functions so the codes below are equivalent:\n\n`[`(x, 1, , )\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    7   13   19\n[2,]    4   10   16   22\n\n\n\nx[1, , ]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    7   13   19\n[2,]    4   10   16   22\n\n\nThe assignment operator for arrays can be written like below where the last argument is the value to replace the indexed array.\n\n`[<-`(x2, 1, , , 0)\n\n, , 1\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]    0    0\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]    0    0\n[2,]   20   23\n[3,]   21   24\n\n\nBelow is similar.\n\nx2[1, , ] <- 0\n\nI say similar because the above actually modifies x2 but the call before that didn’t. Below is the actual equivalent operation.\n\nx2 <- `[<-`(x2, 1, , , 0)\n\n\n\nSolution for indexing\n\n\nindex_first <- function(x) {\n  d <- dim(x)\n  do.call(\"[\", c(list(x, 1), rep(list(bquote()), length(d) - 1)))\n}\n\nindex_first(x)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    7   13   19\n[2,]    4   10   16   22\n\nindex_first(z)\n\n, , 1\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]   NA   NA\n\n, , 2\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]   NA   NA\n\n\n\n\n\nSolution for assignment\n\n\nmodify_first <- function(x, value) {\n  d <- dim(x)\n  do.call(\"[<-\", c(list(x, 1), rep(list(bquote()), length(d) - 1), list(value)))\n}\n\nmodify_first(x, 3)\n\n, , 1\n\n     [,1] [,2]\n[1,]    3    3\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    3    3\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   20   23\n[3,]   21   24\n\nmodify_first(z, 3)\n\n, , 1, 1\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   NA   NA\n\n, , 2, 1\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   NA   NA\n\n, , 1, 2\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   NA   NA\n\n, , 2, 2\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   NA   NA"
  },
  {
    "objectID": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#practice",
    "href": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#practice",
    "title": "Manipulating arrays with dynamic dimensions in R",
    "section": "Practice",
    "text": "Practice\nSo you might wonder when you need such a result. I actually used this for the edibble R-package to create a kind of generalised version of Latin square design, i.e. an array that kind of stitches up multiple Latin squares.\n\nset.seed(1)\nedibble::latin_array(dim = c(3, 3, 3), nt = 3)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    2\n[2,]    3    2    1\n[3,]    2    1    3\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    2    1    3\n[2,]    1    3    2\n[3,]    3    2    1\n\n, , 3\n\n     [,1] [,2] [,3]\n[1,]    3    2    1\n[2,]    2    1    3\n[3,]    1    3    2\n\n\nBeyond the above, I’m not sure who needs to manipulate arrays with dynamic dimensions. If you have a use case, I’d love to know."
  },
  {
    "objectID": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#advanced-r-programming-unit",
    "href": "blog/2022-01-18-manipulating-arrays-in-R/manipulating-arrays-in-r.html#advanced-r-programming-unit",
    "title": "Manipulating arrays with dynamic dimensions in R",
    "section": "Advanced R Programming unit",
    "text": "Advanced R Programming unit\nThe above challenges are sort of challenges that I hope to include in the Advanced R Programming unit that’s planned for Honours level in the Business Analytics major at Monash University. If you want to learn more about R as a programming lanuage (instead of a data analysis tool) then I’d recommend the Advanced R book by Hadley Wickham."
  },
  {
    "objectID": "blog/2022-03-12-maximum-potential/maximum-potential.html",
    "href": "blog/2022-03-12-maximum-potential/maximum-potential.html",
    "title": "Maximum potential",
    "section": "",
    "text": "Ice hockey talent\nIn the beginning of the book, Gladwell presents a hockey player roster shown in Table @ref(tab:hat-tigers). He asks to take a closer look at this roster. Do you notice anything strange about the list?\n\n\n\n\nThe player roster of the 2007 Medicine Hat Tigers (a Canadian hockey team). Do you notice anything unusual?\n \n  \n    No \n    Name \n    Pos \n    Shoots \n    Height \n    Weight \n    Birthdate \n    Hometown \n  \n \n\n  \n    9 \n    Brennan Bosch \n    C \n    R \n    5.666667 \n    173 \n    1988-02-14 \n    Martensville, SK \n  \n  \n    11 \n    Scott Wasden \n    C \n    R \n    6.083333 \n    188 \n    1988-01-04 \n    Westbank, BC \n  \n  \n    12 \n    Colton Grant \n    LW \n    L \n    5.750000 \n    177 \n    1989-03-20 \n    Standard, AB \n  \n  \n    14 \n    Darren Helm \n    LW \n    L \n    6.000000 \n    182 \n    1987-01-21 \n    St. Andrews, MB \n  \n  \n    15 \n    Derek Dorsett \n    RW \n    L \n    5.916667 \n    178 \n    1986-12-20 \n    Kindersley, SK \n  \n  \n    16 \n    Daine Todd \n    C \n    R \n    5.833333 \n    173 \n    1987-01-10 \n    Red Deer, AB \n  \n  \n    17 \n    Tyler Swystun \n    RW \n    R \n    5.916667 \n    185 \n    1988-01-15 \n    Cochrane, AB \n  \n  \n    19 \n    Matt Lowry \n    C \n    R \n    6.000000 \n    186 \n    1988-03-02 \n    Neepawa, MB \n  \n  \n    20 \n    Kevin Undershute \n    LW \n    L \n    6.000000 \n    178 \n    1987-04-12 \n    Medicine Hat, AB \n  \n  \n    21 \n    Jerrid Sauer \n    RW \n    R \n    5.833333 \n    196 \n    1987-09-12 \n    Medicine Hat, AB \n  \n  \n    22 \n    Tyler Ennis \n    C \n    L \n    5.750000 \n    160 \n    1989-10-06 \n    Edmonton, AB \n  \n  \n    23 \n    Jordan Hickmott \n    C \n    R \n    6.000000 \n    183 \n    1990-04-11 \n    Mission, BC \n  \n  \n    25 \n    Jakub Rumpel \n    RW \n    R \n    5.666667 \n    166 \n    1987-01-27 \n    Hrnciarovce, SLO \n  \n  \n    28 \n    Bretton Cameron \n    C \n    R \n    5.916667 \n    168 \n    1989-01-26 \n    Didsbury, AB \n  \n  \n    36 \n    Chris Stevens \n    LW \n    L \n    5.833333 \n    197 \n    1986-08-20 \n    Dawson Creek, BC \n  \n  \n    3 \n    Gord Baldwin \n    D \n    L \n    6.416667 \n    205 \n    1987-03-01 \n    Winnipeg, MB \n  \n  \n    4 \n    David Schlemko \n    D \n    L \n    6.083333 \n    195 \n    1987-05-07 \n    Edmonton, AB \n  \n  \n    5 \n    Trevor Glass \n    D \n    L \n    6.000000 \n    190 \n    1988-01-22 \n    Cochrane, AB \n  \n  \n    10 \n    Kris Russell \n    D \n    L \n    5.833333 \n    177 \n    1987-05-02 \n    Caroline, AB \n  \n  \n    18 \n    Michael Sauer \n    D \n    R \n    6.250000 \n    205 \n    1987-08-07 \n    Sartell, MN \n  \n  \n    24 \n    Mark Isherwood \n    D \n    R \n    6.000000 \n    183 \n    1989-01-31 \n    Abbotsford, BC \n  \n  \n    27 \n    Shayne Brown \n    D \n    L \n    6.083333 \n    198 \n    1989-02-20 \n    Stony Plain, AB \n  \n  \n    29 \n    Jordan Bendfeld \n    D \n    R \n    6.250000 \n    230 \n    1988-02-09 \n    Leduc, AB \n  \n  \n    31 \n    Ryan Holfeld \n    G \n    L \n    5.916667 \n    166 \n    1989-06-29 \n    LeRoy, SK \n  \n  \n    33 \n    Matt Keetley \n    G \n    R \n    6.166667 \n    189 \n    1986-04-27 \n    Medicine Hat, AB \n  \n\n\n\n\n\n\nTable @ref(tab:hat-tigers) data is stored in object mht2007.\n\nprint(mht2007, width = 30)\n\n# A tibble: 25 × 8\n      No Name     Pos   Shoots\n   <dbl> <chr>    <chr> <chr> \n 1     9 Brennan… C     R     \n 2    11 Scott W… C     R     \n 3    12 Colton … LW    L     \n 4    14 Darren … LW    L     \n 5    15 Derek D… RW    L     \n 6    16 Daine T… C     R     \n 7    17 Tyler S… RW    R     \n 8    19 Matt Lo… C     R     \n 9    20 Kevin U… LW    L     \n10    21 Jerrid … RW    R     \n# … with 15 more rows, and 4\n#   more variables:\n#   Height <dbl>,\n#   Weight <dbl>,\n#   Birthdate <date>,\n#   Hometown <chr>\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\nDid you notice anything unusual from the above table? If you didn’t that’s okay. Let’s instead look at Figure @ref(fig:mht-2007-bar) which shows the frequency of the birth month that the players are born. Now do you notice something?\n\nmht2007 %>% \n  mutate(month = factor(month(Birthdate), levels = 1:12, labels = month.abb)) %>% \n  ggplot(aes(month)) +\n  geom_bar(fill = \"#79003e\") +\n  scale_x_discrete(limits = month.abb) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\nThe barplot of the birth month of the Medicine Hat Tigers 2007 hockey players.\n\n\n\n\nWithout doing any statistical tests, you probably can see from Figure @ref(fig:mht-2007-bar) that there is an over-representation of players born in January. Gladwell postulates that this is a result of Canada’s eligibility cut-off for age-class hockey being January 1st. To explain further, coaches in Canada start training selected children at the age of 9 or 10. In preadolescence, a few months of gap can show a big difference in physical maturity, so for children born in the same year, the coaches tend to select the ones born earlier in the year. These selected children then get many more practice than the children who are not selected, and what started as a frivolous difference due to the month you were born turns into a big difference in talent in future.\nI wanted to validate the claim about the birth month so I searched and scraped the player data at Medicine Hot Tiger from https://tigershockey.com/roster/ using RSelenium and rvest packages. The resulting data is stored in the object roster which include the player information for the following games:\n\nroster %>% \n  pull(WHL) %>% \n  unique()\n\n [1] \"2021 - 22 Regular Season\" \"2021 Pre Season\"         \n [3] \"2020 - 21 Regular Season\" \"2019 - 20 Regular Season\"\n [5] \"2019 Pre Season\"          \"2019 WHL Playoffs\"       \n [7] \"2018 - 19 Regular Season\" \"2018 Pre Season\"         \n [9] \"2018 WHL Playoffs\"        \"2017 - 18 Regular Season\"\n[11] \"2017 Pre Season\"          \"2017 WHL Playoffs\"       \n[13] \"2016 - 17 Regular Season\" \"2016 Pre Season\"         \n[15] \"16 Tie Break\"             \"2015-16 Regular Season\"  \n[17] \"2015 Preseason\"           \"2015 WHL Playoffs\"       \n[19] \"2014-15 Regular Season\"   \"2014 Preseason\"          \n[21] \"2014 WHL Playoffs\"        \"2013-14 Regular Season\"  \n[23] \"2013 WHL Preseason\"       \"2013 WHL Playoffs\"       \n[25] \"2012-13 Regular Season\"   \"2012 WHL Preseason\"      \n[27] \"2012 WHL Playoffs\"        \"2011-12 Regular Season\"  \n[29] \"2011 WHL Preseason\"       \"2011 WHL Playoffs\"       \n[31] \"2010-11 Regular Season\"   \"2010 WHL Playoffs\"       \n[33] \"2009-10 Regular Season\"   \"2009 WHL Playoffs\"       \n[35] \"2008-09 Regular Season\"   \"2008 WHL Playoffs\"       \n[37] \"2007-08 Regular Season\"   \"2007 WHL Playoffs\"       \n[39] \"2006-07 WHL Season\"       \"2006 WHL Playoffs\"       \n[41] \"2005-06 WHL Season\"       \"2005 WHL Playoffs\"       \n[43] \"2004-05 WHL Season\"       \"2004 WHL Playoffs\"       \n[45] \"2003-2004 WHL Season\"     \"2003 WHL Playoffs\"       \n[47] \"2002-03 WHL Season\"       \"2001-2002 WHL Season\"    \n[49] \"2000-2001 WHL Season\"     \"1999-2000 WHL Season\"    \n[51] \"1998-99 WHL Season\"       \"1997-98 WHL Season\"      \n[53] \"1997 WHL Playoffs\"        \"1996-97 WHL Season\"      \n[55] \"1996 WHL Playoffs\"       \n\n\nAfter removing duplicate records of the players that appear across multiple games, I plot the frequency of the birth month of the rostered Medicine Hat Tigers hockey players from 1996 to 2021 in Figure @ref(fig:roster-bar). The frequency of players born in January are not strikingly over-represented with a larger sample size but it is noticeable that there are more players born in the first half of the year than second half of the year.\n\nroster_unique <- roster %>% \n  mutate(month = factor(month(DOB), levels = 1:12, labels = month.abb)) %>% \n  distinct(Player, .keep_all = TRUE)\n\nggplot(roster_unique, aes(month)) +\n  geom_bar(fill = \"#79003e\") +\n  scale_x_discrete(limits = month.abb) +\n  scale_y_continuous(expand = c(0, 0))\n\nWarning: Removed 7 rows containing non-finite values (stat_count).\n\n\n\n\n\nThe barplot of the birth month of the Medicine Hat Tigers hockey players from 1996 to 2021.\n\n\n\n\nIf you are keen, you can do some statistical tests to confirm this assuming equal probability of a person being born in the first or second half of the year.\n\nbirth_count <- roster_unique %>% \n  mutate(first_half = month(DOB) < 7) %>% \n  group_by(first_half) %>% \n  count()\n\nbirth_count\n\n# A tibble: 3 × 2\n# Groups:   first_half [3]\n  first_half     n\n  <lgl>      <int>\n1 FALSE         76\n2 TRUE         166\n3 NA             7\n\n\n\nchisq.test(birth_count$n[1:2], p = c(0.5, 0.5))\n\n\n    Chi-squared test for given probabilities\n\ndata:  birth_count$n[1:2]\nX-squared = 33.471, df = 1, p-value = 7.233e-09\n\n\n\n\nChanging the environment for your growth\nYou can extrapolate the ice hockey birth month scenario to other situations and Gladwell presents more examples of super successful (“outlier”) men like Bill Gates, Eric Schmidt, Steve Jobs and so on, of how essential they were in the right place at the right time. Sadly, Gladwell didn’t take the opportunity to discuss about “women outliers” or highlight an example about success based on sex, which very much like birth month is a random assignment beyond an individual’s control, but can make a difference in one’s career.\nGladwell’s writing cemented the idea within me of the importance of the environment particularly when you are still young. E.g. if you are busy trying to find a safe place for you and your family because of the Ukraine-Russia war, you’ll have little opportunity to do anything else no matter how great of a talent you have.\nThose who are “successful” tend to be the ones who had the environment working in their favour earlier (if not most of the time) in their career. This is not to say they don’t have talent or didn’t work hard, but the tragedy in all this is that those who have talent but didn’t have the environment to achieve their maximum potential. I can see the traces of my thought on twitter about changing the environment if it’s not working for you creeping up every now and then. (Changing environments has costs though so I realise my advice doesn’t work for everyone.)\n\n\nYes this happens a lot. If you an ECR, it’s best to get out of that environment. You are young and it’s the best time to GROW. Surround yourself with people who are better in the skills you care about. If they are not in your workplace, go outside of workplace. Meetup, online\n\n— Emi Tanaka (田中愛美) 💉💉💉 (@statsgen) March 7, 2019\n\n\n\n\nIf you are the solo RSE or you don’t have anyone to talk deeply about the software engineering aspects, I don’t know if there will be motivation to stay in that kind of environment when you have other choices. (2/2)\n\n— Emi Tanaka (田中愛美) 💉💉💉 (@statsgen) November 17, 2021\n\nAbove predicates on the goal of personal growth, but “success” ultimately comes in many forms. Personally, I feel frustrated when I feel that the environment gets in my way of my personal growth and this tends to drive me to change the environment. There’s a limit to what you can change though, and there’s a part of me that knows that I’m driving myself into a wall getting frustrated at every turn and I’ve got to chill. (I’m sorry if you’re ever on the receiving end of my frustration - but hey maybe you deserve it!… I kid :P)\n\n\nChanging the environment for others’ growth\nThere’s been a few times in my life where the upper management was quite bad that it was causing havoc for those under the management and there is widespread discontent. Every time this happens, I always think about how I don’t want to be like that upper management, but I equally fear that I am going to be, perhaps unknowingly, like that when I’m in the same position. So I occasionally remind myself that I shouldn’t fault people, when you don’t know what other things are driving the behaviour or decision. But I’m no saint, so I still have a long way to go though to be that understanding and I might poke fun of the situation in a passive-aggressive drawing 🎨\n\n\nFun to draw again 💃 pic.twitter.com/3uHQLi8biA\n\n— Emi Tanaka (田中愛美) 💉💉💉 (@statsgen) February 18, 2019\n\n\n\n\nBranding and management gone wrong. \"Precision Pen\" pic.twitter.com/SVd6uyxrSr\n\n— Emi Tanaka (田中愛美) 💉💉💉 (@statsgen) March 17, 2019"
  },
  {
    "objectID": "blog/2022-04-27-new-beginnings/new-beginnings.html",
    "href": "blog/2022-04-27-new-beginnings/new-beginnings.html",
    "title": "To new beginnings",
    "section": "",
    "text": "My old office had a pretty nice view of the hex wall but I don’t know where it is now. Last I saw it was clearly labelled to be moved to level 3 corridors but maybe it’s yet to be moved. Impressively, they did manage to bring my big and small whiteboard as well as the large corkboard in my old office – now it just needs to be hanged and I need to figure out where the whiteboard markers are stored.\n\n\nYou should check out the view of the corridor from my office ;) pic.twitter.com/8L0fCf6F0P\n\n— Emi Tanaka (田中愛美) 💉💉💉 ((statsgen?)) August 1, 2020\n\n\nWhile that’s happening, in the weekends I saw some twitter posts (yet again) about shade against academia. The specific post was referring to the lower pay in academia and said in industry there’s no penalty in walking away from a job with bad work culture (insinuating that’s not the case in academia). Give it another week or so, I’m sure I’ll see another post against the academic culture, a #quitlit post or how great an industry position is.\nBased on the frequency you see these posts, you’d think academia is an awful place. It’s also not hard to find people who’ll affirm your belief. Then why do people stay in academia? There’s one reason I hear quite often – they get freedom. That answer always remind me of a page from this book I saw years ago – this page still makes me laugh 😂\n\nThere’s a well known experimental study by L. Festinger and Carlsmith (1959) that studied subjects that had to do repetitive, monotonous tasks and was told to lie to the next “subject” (actually a hired accomplice) that the task was interesting and enjoyable. Some subjects were paid $1 for lying while others were paid $20. There was a control group that didn’t have to lie. There were 20 subjects in each of the three groups. After the task, each subject was asked to rate (on a scale of -5 to +5 where -5 is dislike, and +5 is like) how much they enjoyed the tasks. The subjects that were paid $1 reported on average a higher level of enjoyment (1.35) than subjects who were paid $20 (-0.50); the average level of enjoyment for control group was -0.45.\nThe results aligned with the theory of cognitive dissonance by Leon Festinger (1957), which suggests that we have an inner drive to hold our cognitive elements (attitudes, perceptions, knowledge and beliefs) in harmony and we feel discomfort when some of these elements are inconsistent. The study by L. Festinger and Carlsmith (1959) suggested that people who were paid $1 to lie felt they had to justify the poor payment by convincing themselves that they actually enjoyed the task, while those that were paid $20 were well rewarded and did not experience cognitive dissonance.\nThe experimental result in L. Festinger and Carlsmith (1959) reminded me of the often touted reason where industry is better than academia: money, and the academics that give reasons of why they stay in academia, despite the lower pay. If you are an academic, did you really choose to be in academia for some higher purpose? Or do you just stay because we tend to succumb to inertia and that was the path of least resistance? I tend to be skeptical of any rosy picture that either side presents. I don’t deny though that I get affected by the strong emotions that people display against academia – more so, because I know some comments are true – academic culture and system needs to improve – but the eternal question is who’s going to champion the change? The way I see it, it’s a collective responsibility so everyone should contribute to make it a better place, with more responsibility on those in higher echelon.\nReality is complex and as any job, academic job is a mix of good, bad, joy, and tediuous. Sometimes it’s just the small acts of people around that consider your best interest at heart – see you as a person and not an expendable tool – that makes it worthwhile even if the system doesn’t work for you. I can’t say academia is bad when my colleague is considerate of me, telling me of a pathway so I can get a bigger office, and another colleague allocating himself the smaller office so a large office can be allocated to someone else (despite himself being a former head of department and a professor). There are some bad apples of course, but plenty of good people in academia.\nIf a workplace culture is bad or it’s not working well for you though, by all means walk away – maybe giving a reasonable chance to see if people take actions to rectify the issues first. In my relatively short career, I’ve butted heads a number of times already (concidentally all professors – yeah, I’m harder on people with power because I expect better of them) so I won’t be surprised a number of people dislike me, but also at the same time, I know there are plenty of people that appreciate me for my conduct and contributions. If anything, it’s the difficult times that can be revealing of character and bring people together. It’s always the people’s conduct that make the workplace great or not – or at least bearable.\n\n\n\n\nReferences\n\nFestinger, L, and J M Carlsmith. 1959. “Cognitive Consequences of Forced Compliance.” Journal of Abnormal Psychology 58 (2): 203–10. https://doi.org/10.1037/h0041593.\n\n\nFestinger, Leon. 1957. “A Theory of Cognitive Dissonance.”"
  },
  {
    "objectID": "blog/2022-02-20-color-considerations/color-considerations.html",
    "href": "blog/2022-02-20-color-considerations/color-considerations.html",
    "title": "Colorblind checks for qualitative palettes",
    "section": "",
    "text": "Function to generate plot for colorblind friendly check\n\n\nlibrary(ggplot2)\nlibrary(farver)\nlibrary(colorspace)\ncheck_colorblindness <- function(colors, ncol = 3, label = TRUE) {\n  ncolors <- length(colors)\n  nrow <- ceiling(ncolors / ncol)\n  cond <- c(\"Original\", \"Deutan\", \"Protan\", \"Tritan\")\n  ncond <- length(cond)\n  \n  df <- data.frame(color = c(colors, deutan(colors), protan(colors), tritan(colors)),\n                   cond = rep(cond, each = ncolors),\n                   x = rep(rep(1:ncol, length.out = ncolors), times = ncond),\n                   y = rep(rep(1:nrow, each = ncol)[1:ncolors], times = ncond)) %>% \n    mutate(cond = factor(cond, levels = .env$cond))\n  \n  \n  g <- ggplot(df, aes(x, y, fill = I(color))) +\n    geom_tile(color = \"black\", size = 1.3) +\n    theme_void() +\n    coord_equal() +\n    facet_wrap(~cond, ncol = 2) +\n    scale_y_reverse()\n  \n  if(label) {\n      g + geom_text(aes(label = color, color = I(label_col)), \n              data = function(data) data %>% \n                filter(cond == \"Original\") %>% \n                mutate(hcl = decode_colour(colors, to = \"hcl\"),\n                       label_col = ifelse(hcl[, \"l\"] > 50, \"black\", \"white\")))\n  } else {\n    g\n  } \n}"
  },
  {
    "objectID": "blog/2022-02-20-color-considerations/color-considerations.html#r-code-for-easy-copying",
    "href": "blog/2022-02-20-color-considerations/color-considerations.html#r-code-for-easy-copying",
    "title": "Colorblind checks for qualitative palettes",
    "section": "R code for easy copying",
    "text": "R code for easy copying\n\n\n### High contrast \nc(\"#FFFFFF\", \"#DDAA33\", \"#BB5566\", \"#004488\", \"#000000\")\n\n### Pale \nc(\"#BBCCEE\", \"#CCEEFF\", \"#CCDDAA\", \"#EEEEBB\", \"#FFCCCC\", \"#DDDDDD\"\n)\n\n### Dark \nc(\"#222255\", \"#225555\", \"#225522\", \"#666633\", \"#663333\", \"#555555\"\n)\n\n### Bright \nc(\"#4477AA\", \"#66CCEE\", \"#228833\", \"#CCBB44\", \"#EE6677\", \"#AA3377\", \n\"#BBBBBB\")\n\n### Vibrant \nc(\"#0077BB\", \"#33BBEE\", \"#009988\", \"#EE7733\", \"#CC3311\", \"#EE3377\", \n\"#BBBBBB\")\n\n### Medium constrast \nc(\"#FFFFFF\", \"#EECC66\", \"#EE99AA\", \"#6699CC\", \"#997700\", \"#994455\", \n\"#004488\", \"#000000\")\n\n### Okabe Ito \nc(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \n\"#CC79A7\", \"#000000\")\n\n### Light \nc(\"#77AADD\", \"#99DDFF\", \"#44BB99\", \"#BBCC33\", \"#AAAA00\", \"#EEDD88\", \n\"#EE8866\", \"#FFAABB\", \"#DDDDDD\")\n\n### Muted \nc(\"#332288\", \"#88CCEE\", \"#44AA99\", \"#117733\", \"#999933\", \"#DDCC77\", \n\"#CC6677\", \"#882255\", \"#AA4499\", \"#DDDDDD\")\n\n### Safe \nc(\"#88CCEE\", \"#CC6677\", \"#DDCC77\", \"#117733\", \"#332288\", \"#AA4499\", \n\"#44AA99\", \"#999933\", \"#882255\", \"#661100\", \"#6699CC\", \"#888888\"\n)\n\n### Monash primary \nc(blue = \"#006DAE\", black = \"#000000\", white = \"#FFFFFF\", gray80 = \"#5A5A5A\", \ngray50 = \"#969696\", gray10 = \"#E6E6E6\")\n\n### Monash secondary \nc(blue = \"#027EB6\", purple = \"#746FB2\", fuchsia = \"#9651A0\", \nruby = \"#C8008F\", pink = \"#ee64a4\", red = \"#EE0220\", orange = \"#D93F00\", \number = \"#795549\", olive = \"#6F7C4D\", green = \"#008A25\")"
  },
  {
    "objectID": "blog/2022-02-20-color-considerations/color-considerations.html#closer-look",
    "href": "blog/2022-02-20-color-considerations/color-considerations.html#closer-look",
    "title": "Colorblind checks for qualitative palettes",
    "section": "Closer look",
    "text": "Closer look\n\n\n\n\n\nHigh contrast palette: #FFFFFF, #DDAA33, #BB5566, #004488, #000000.\n\n\n\n\n\n\n\n\n\n\n\n\nPale palette: #BBCCEE, #CCEEFF, #CCDDAA, #EEEEBB, #FFCCCC, #DDDDDD.\n\n\n\n\n\n\n\n\n\n\n\n\nDark palette: #222255, #225555, #225522, #666633, #663333, #555555.\n\n\n\n\n\n\n\n\n\n\n\n\nBright palette: #4477AA, #66CCEE, #228833, #CCBB44, #EE6677, #AA3377, #BBBBBB.\n\n\n\n\n\n\n\n\n\n\n\n\nVibrant palette: #0077BB, #33BBEE, #009988, #EE7733, #CC3311, #EE3377, #BBBBBB.\n\n\n\n\n\n\n\n\n\n\n\n\nMedium constrast palette: #FFFFFF, #EECC66, #EE99AA, #6699CC, #997700, #994455, #004488, #000000.\n\n\n\n\n\n\n\n\n\n\n\n\nOkabe Ito palette: #E69F00, #56B4E9, #009E73, #F0E442, #0072B2, #D55E00, #CC79A7, #000000.\n\n\n\n\n\n\n\n\n\n\n\n\nLight palette: #77AADD, #99DDFF, #44BB99, #BBCC33, #AAAA00, #EEDD88, #EE8866, #FFAABB, #DDDDDD.\n\n\n\n\n\n\n\n\n\n\n\n\nMuted palette: #332288, #88CCEE, #44AA99, #117733, #999933, #DDCC77, #CC6677, #882255, #AA4499, #DDDDDD.\n\n\n\n\n\n\n\n\n\n\n\n\nSafe palette: #88CCEE, #CC6677, #DDCC77, #117733, #332288, #AA4499, #44AA99, #999933, #882255, #661100, #6699CC, #888888.\n\n\n\n\n\n\n\n\n\n\n\n\nMonash primary palette: #006DAE, #000000, #FFFFFF, #5A5A5A, #969696, #E6E6E6.\n\n\n\n\n\n\n\n\n\n\n\n\nMonash secondary palette: #027EB6, #746FB2, #9651A0, #C8008F, #ee64a4, #EE0220, #D93F00, #795549, #6F7C4D, #008A25."
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#making-your-own-title-slide",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#making-your-own-title-slide",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Making your own title slide",
    "text": "Making your own title slide\nBoth xaringan and Quarto revealjs slides create a default title slide if you supply the title in the YAML.\nxaringan\nIn xaringan, you can disable this by using seal: false.\nQuarto revealjs\nFor Quarto revealjs, replace the title: with pagetitle: in the YAML or alternatively do not include title in the YAML. The benefit of the former approach is that the metadata for the title is automatically created for you in the HTML output.\n---\npagetitle: \"My title\"\n---"
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#starting-a-new-slide",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#starting-a-new-slide",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Starting a new slide",
    "text": "Starting a new slide\nxaringan\nIn xaringan, a new slide is started by separating the content with --- in a new line where care needs to be taken not to have spaces after it.\nQuarto revealjs\nIn Quarto revealjs slides, there are two primary ways to start a new slide:\n\n--- just like in xaringan and\na first or second level header, i.e. a line starting with # or ##."
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#shortcut-for-div-and-span-with-css-classes",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#shortcut-for-div-and-span-with-css-classes",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Shortcut for div and span with CSS classes",
    "text": "Shortcut for div and span with CSS classes\nxaringan\nIn xaringan, div element with content, say “My content.”, and CSS class, say myclass, are created with\n.myclass[\nMy content.\n]\nThe above when processed by remark.js becomes:\n<div class=\"myclass\">\nMy content.\n</div>\nSimilary for span element, the shortcut in xaringan is:\n.myclass[My content.]\nwhich becomes\n<span class=\"myclass\">My content.</span>\nThe difference between the two being that there is a new line required before the ] for the div element.\nQuarto revealjs\nIn Quarto revealjs slides, the shortcut for the div and span elements are (I believe) from native Pandoc divs and spans. This was actually one of the biggest reasons I wanted to switch from xaringan. All Rmd documents support Pandoc divs and spans except in xaringan where the markdown content is processed by remark.js instead of Pandoc. The lack of consistency even made me write my own naive javascript to mimic Pandoc div and span for xaringan, but I still wanted the native support.\nSo you can create a div element in Quarto revealjs by:\n::: myclass\n\nMy content.\n\n:::\nor equivalently,\n::: {.myclass}\n\nMy content.\n\n:::\nIn fact, it’s not limited to CSS classes but ids as well. E.g.\n::: {#myid}\n\nMy content.\n\n:::\nis the same as\n<div id=\"myid\">\nMy content.\n</div>\nFor a span element in Quarto revealjs, it will be like below\n[My content.]{.myclass}\nwhere this is equivalent to below:\n<span class=\"myclass\">My content.</span>"
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#slide-css-classes",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#slide-css-classes",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Slide CSS classes",
    "text": "Slide CSS classes\nxaringan\nIn xaringan, a CSS class maybe specified to the whole slide by:\nclass: myclass\nI used this sometimes to define a slide with different background colors.\nQuarto revealjs\nThe HTML layout for revealjs slides is actually quite different to the layout for remarkjs slides. I won’t go into too much details this time, but the main thing is that a slide content is written within <section></section> and separate to this is a background element and other div (like footer and slide numbers). The latter elements are not nested within the slide itself, which makes the concept of applying the CSS class to the whole slide different in revealjs compared to xaringan/remarkjs.\nTo apply a CSS class to a slide with no title, you can do below:\n## {.myclass}\nand if you have a title, just write the title first before defining the class like below:\n## My title {.myclass}\nIf you want to apply it to the slide background then only specific attributes work, e.g. below changes the background color of the slide to red:\n## {background-color=\"red\"}"
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#columns",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#columns",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Columns",
    "text": "Columns\nxaringan\nIf you used the default xaringan, you may have used .left[] and .right[] to make two columns. These actually are setting the attributes of the elements to float: left; and float:right;, respectively, with width: 48%;.\nQuarto revealjs\nFor multiple columns in Quarto revealjs, you can set something like below to make two columns, one with 40% width and the other with 60% width.\n:::: {.columns}\n\n::: {.column width=\"40%\"}\nLeft column\n:::\n\n::: {.column width=\"60%\"}\nRight column\n:::\n\n::::\nYou can find more details here."
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#incremental-slides",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#incremental-slides",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Incremental slides",
    "text": "Incremental slides\nBy incremental slides, I mean slides where you want to reveal the content of slide one at a time without rewriting separate slides with the same past content.\nxaringan\nIn xaringan, you can use --. You can also use {{content}} to specify where the new content after -- will be inserted. E.g.\nSlide 1 \n\n--\n\n{{content}}\n\nThis content will only appear in next slide below \"Slide 1\".\n\n--\n\nThis content will appear on top of the last sentence but below \"Slide 1\".\n\nQuarto revealjs\nThe -- in xaringan is the same as the . . . (three dots separated by spaces) in Quarto revealjs.\n\nSlide 1 \n\nFirst content\n\n. . . \n\nSecond content after pause\n\nA similar feat to {{content}} in xaringan can be achieved by using fragments in Quarto revealjs, like below:\n\nSlide 1 \n\n::: {.fragment fragment-index=2}\nThis content will appear on top of the last sentence but below \"Slide 1\".\n:::\n\n::: {.fragment fragment-index=1}\nThis content will only appear in next slide below \"Slide 1\".\n:::\n\nYou can find more details here but the basic idea is that any HTML elements that have the class “fragment” will be incrementally shown and you can control the sequence of appearance by specifying the number for the attribute in fragment-index.\nThis is of course painful to do if you have a list! For this, there is a special case where incremental lists can be specified by class “incremental” like below:\n::: {.incremental}\n- Task A\n- Task B\n:::\nMore details on incremental list can be found here."
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#slide-names",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#slide-names",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Slide names",
    "text": "Slide names\nxaringan\nIn xaringan, you can use the name: myname to set slide names which can then be referenced in other parts of the slides by say [see here](#myname).\nQuarto revealjs\nIn Quarto revealjs, slides automatically have names that are transformed versions of the slide title (spaces replaced with -, lower cases, etc). But if you want to apply a custom name then you can pass define the attribute in the top level header of the slide:\n## Slide Title {#myname}"
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#uncounted-slides",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#uncounted-slides",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Uncounted slides",
    "text": "Uncounted slides\nxaringan\nYou can use count: false to not increment the slide number for particular slides.\nQuarto revealjs\nIn Quarto revealjs, you can choose to not count the slide by setting visibility=\"uncounted\" in the top level header:\n## Slide Title {visibility=\"uncounted\"}"
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#exclude-slides",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#exclude-slides",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Exclude slides",
    "text": "Exclude slides\nxaringan\nYou can use exclude: true to not increment the slide number for particular slides.\nQuarto revealjs\nIn Quarto revealjs, you can specify the attribute visibility=\"hidden\" in the top level header for the slide:\n## Slide Title {visibility=\"hidden\"}"
  },
  {
    "objectID": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#layouts-and-templates",
    "href": "blog/2022-07-11-transitioning-from-xaringan-to-quarto-revealjs/transitioning-from-xaringan-to-quarto-revealjs.html#layouts-and-templates",
    "title": "How to transition from xaringan to Quarto revealjs",
    "section": "Layouts and templates",
    "text": "Layouts and templates\nThe layout and template feature allowed you to use the same layout in subsequent slides in xaringan/remark.js. I don’t think there is an equivalent feature in Quarto revealjs for this."
  },
  {
    "objectID": "blog/2022-01-16-anime-titles/anime-titles.knit.html",
    "href": "blog/2022-01-16-anime-titles/anime-titles.knit.html",
    "title": "Are anime titles getting longer?",
    "section": "",
    "text": "Click Me\n\nto see all code in this article. You can also find the link to the source Rmd file at the footer.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(anidb)\ntheme_set(\n  theme(panel.background = element_rect(fill = NA),\n        panel.grid = element_line(color = \"#f6e5ee\"),\n        axis.text = element_text(color = \"#79003e\"),\n        axis.line = element_line(color = \"#79003e\", size = 0.7),\n        axis.ticks.length = unit(1.4, \"mm\"),\n        axis.ticks = element_line(color = \"#79003e\", size = 0.7),\n        axis.title = element_text(color = \"#79003e\", face = \"bold\"),\n        strip.background = element_rect(color = \"#79003e\",\n                                        fill = \"#AD0059\"),\n        strip.text = element_text(color = \"white\"),\n        plot.title.position = \"plot\",\n        plot.title = element_text(color = \"#79003e\", face = \"bold\")))\n\n\n\n\ndb <- officialtitles %>% \n  mutate(ntitle = nchar(title_primary))\n\nanime_origin <- db %>% \n  count(origin) %>% \n  deframe()\n\ndbl <- db %>% \n  arrange(desc(ntitle)) %>% \n  slice(1:10)\n\n\nAniDB is a website that hosts extensive information on anime from China, Japan and Korea. There are currently information on 13,951 anime of which 91% originated from Japan.\nAs an anime lover, I’ve watched over 700 anime (which is still less than 5% in the whole database!) but one thing I noticed over recent years is that some anime titles are bizzarely long… or more like anime titles are becoming sentences. To explore this, I decided to use the anidb R-package to look at the data.\nFirst note that anime titles come in many forms. For example,\n\n“新世紀エヴァンゲリオン” is the Japanese title,\n“Shinseiki Evangelion” is the primary title (the official title in the country of origin but in romanized form), and\n“Neon Genesis Evangelion” is the English title. The English title may be unavailable if the anime is not licensed for English audiences.\n\nIn the following explorations, I use the primary title.\nFigure @ref(fig:title-length-distribution) shows that the distribution of the primary title length. We can see that most anime titles are less than 70 characters but there are some Japanese anime title that are double this length. The top 25 animes have title length greater than 107 characters.\n\n\nggplot(db, aes(ntitle)) +\n  geom_histogram(binwidth = 1, fill = \"#79003e\") +\n  labs(x = \"The length of the romanised primary anime title by county of origin\", \n       y = \"Count\") + \n  facet_grid(origin ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\nTitle length of Japanese anime are right skewed.\n\n\n\n\nThe five longest titles from longest to shortest are:\n\n“Honzuki no Gekokujou: Shisho ni Naru Tame ni wa Shudan o Erande Iraremasen - Eustachius no Shitamachi Sennyuu Daisakusen / Corinna-sama no Otaku Houmon”\n“Buta no Gotoki Sanzoku ni Torawarete Shojo o Ubawareru Kyonyuu Himekishi & Onna Senshi: Zettai Chinpo Nanka ni Maketari Shinai!! The Animation”\n“Yahari Ore no Seishun LoveCome wa Machigatte Iru. Kochira to Shite mo Karera Kanojora no Yukusue ni Sachi Ookaran Koto o Negawazaru o Enai.”\n“Yuusha ni Narenakatta Ore wa Shibushibu Shuushoku o Ketsui Shimashita.: Yuusha ni Narenakatta Ore no Imouto ga Joukyou Shite Kimashita.”\n“Dungeon ni Deai o Motomeru no wa Machigatte Iru Darouka: Familia Myth - Dungeon ni Onsen o Motomeru no wa Machigatte Iru Darouka”\n\n\n\ninfo <- anime_info(as.character(dbl$aid)) %>% \n  left_join(dbl, by = \"aid\")\n\n\nBecause of AniDB’s limit on API call (multiple requests can get you banned easily – turns out that the limit is quite small; about 13-14 calls already got me banned…), I’m going to just study the top 25 anime in terms of title length.\nFigure @ref(fig:release-date) suggest that super long titles are more common in the last decade than in the past. But the analysis is only based on top 25 anime with the longest titles so it could benefit from more extensive study.\n\n\nggplot(info, aes(start_date, ntitle)) + \n  geom_point(color = \"#79003e\") + \n  labs(x = \"Start date\", y = \"Title length\")\n\n\n\n\n\n\n\nTop 25 anime in terms of title length. Looks like super long titles occur more in the last decade. Top 6 anime with the longest titles are all released after 2010."
  },
  {
    "objectID": "blog/2022-01-16-anime-titles/anime-titles.html",
    "href": "blog/2022-01-16-anime-titles/anime-titles.html",
    "title": "Are anime titles getting longer?",
    "section": "",
    "text": "Click Me\n\nto see all code in this article. You can also find the link to the source Rmd file at the footer.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(anidb)\ntheme_set(\n  theme(panel.background = element_rect(fill = NA),\n        panel.grid = element_line(color = \"#f6e5ee\"),\n        axis.text = element_text(color = \"#79003e\"),\n        axis.line = element_line(color = \"#79003e\", size = 0.7),\n        axis.ticks.length = unit(1.4, \"mm\"),\n        axis.ticks = element_line(color = \"#79003e\", size = 0.7),\n        axis.title = element_text(color = \"#79003e\", face = \"bold\"),\n        strip.background = element_rect(color = \"#79003e\",\n                                        fill = \"#AD0059\"),\n        strip.text = element_text(color = \"white\"),\n        plot.title.position = \"plot\",\n        plot.title = element_text(color = \"#79003e\", face = \"bold\")))\n\n\n\n\ndb <- officialtitles %>% \n  mutate(ntitle = nchar(title_primary))\n\nanime_origin <- db %>% \n  count(origin) %>% \n  deframe()\n\ndbl <- db %>% \n  arrange(desc(ntitle)) %>% \n  slice(1:10)\n\n\nAniDB is a website that hosts extensive information on anime from China, Japan and Korea. There are currently information on 13,951 anime of which 91% originated from Japan.\nAs an anime lover, I’ve watched over 700 anime (which is still less than 5% in the whole database!) but one thing I noticed over recent years is that some anime titles are bizzarely long… or more like anime titles are becoming sentences. To explore this, I decided to use the anidb R-package to look at the data.\nFirst note that anime titles come in many forms. For example,\n\n“新世紀エヴァンゲリオン” is the Japanese title,\n“Shinseiki Evangelion” is the primary title (the official title in the country of origin but in romanized form), and\n“Neon Genesis Evangelion” is the English title. The English title may be unavailable if the anime is not licensed for English audiences.\n\nIn the following explorations, I use the primary title.\nFigure @ref(fig:title-length-distribution) shows that the distribution of the primary title length. We can see that most anime titles are less than 70 characters but there are some Japanese anime title that are double this length. The top 25 animes have title length greater than 107 characters.\n\n\nggplot(db, aes(ntitle)) +\n  geom_histogram(binwidth = 1, fill = \"#79003e\") +\n  labs(x = \"The length of the romanised primary anime title by county of origin\", \n       y = \"Count\") + \n  facet_grid(origin ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\nTitle length of Japanese anime are right skewed.\n\n\n\n\nThe five longest titles from longest to shortest are:\n\n“Honzuki no Gekokujou: Shisho ni Naru Tame ni wa Shudan o Erande Iraremasen - Eustachius no Shitamachi Sennyuu Daisakusen / Corinna-sama no Otaku Houmon”\n“Buta no Gotoki Sanzoku ni Torawarete Shojo o Ubawareru Kyonyuu Himekishi & Onna Senshi: Zettai Chinpo Nanka ni Maketari Shinai!! The Animation”\n“Yahari Ore no Seishun LoveCome wa Machigatte Iru. Kochira to Shite mo Karera Kanojora no Yukusue ni Sachi Ookaran Koto o Negawazaru o Enai.”\n“Yuusha ni Narenakatta Ore wa Shibushibu Shuushoku o Ketsui Shimashita.: Yuusha ni Narenakatta Ore no Imouto ga Joukyou Shite Kimashita.”\n“Dungeon ni Deai o Motomeru no wa Machigatte Iru Darouka: Familia Myth - Dungeon ni Onsen o Motomeru no wa Machigatte Iru Darouka”\n\n\n\ninfo <- anime_info(as.character(dbl$aid)) %>% \n  left_join(dbl, by = \"aid\")\n\n\nBecause of AniDB’s limit on API call (multiple requests can get you banned easily – turns out that the limit is quite small; about 13-14 calls already got me banned…), I’m going to just study the top 25 anime in terms of title length.\nFigure @ref(fig:release-date) suggest that super long titles are more common in the last decade than in the past. But the analysis is only based on top 25 anime with the longest titles so it could benefit from more extensive study.\n\n\nggplot(info, aes(start_date, ntitle)) + \n  geom_point(color = \"#79003e\") + \n  labs(x = \"Start date\", y = \"Title length\")\n\n\n\n\n\n\n\nTop 25 anime in terms of title length. Looks like super long titles occur more in the last decade. Top 6 anime with the longest titles are all released after 2010."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Getting the most out of your experimental data with design\n\n\n\n\n\nThe content of this blog post is originally published in the Biometric Bulletin (2022) Volume 39 Issue 4.\n\n\n\n\n\n\nDec 12, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAffective colors in data visualisation\n\n\n\n\n\n\n\ncolor\n\n\n\n\nThis post extracts the colors and its frequency distribution from an experiment where participants were required to make a five color palette based on certain set of emotions.\n\n\n\n\n\n\nOct 15, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nedibble experimental design with sensory discrimination tests\n\n\n\n\n\n\n\nR\n\n\nexperimental design\n\n\nedibble\n\n\n\n\nCan Australians distinguish the true taste of Vegemite? Designing an experiment with sensory discrimination test using the edibble package.\n\n\n\n\n\n\nJul 30, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to transition from xaringan to Quarto revealjs\n\n\n\n\n\n\n\nQuarto\n\n\nxaringan\n\n\nrevealjs\n\n\nremarkjs\n\n\n\n\nThis post shows a feature in xaringan slides (powered by remark.js) that is roughly equivalent in Quarto revealjs slides.\n\n\n\n\n\n\nJul 11, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcademic ranks\n\n\n\n\n\nDifferent countries adopt a different system for academic ranks. This posts show a mapping of academic ranks across Australian, NZ, UK & North American systems.\n\n\n\n\n\n\nJun 30, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo new beginnings\n\n\n\n\n\n\n\nlife\n\n\n\n\n🎉\n\n\n\n\n\n\nApr 27, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaximum potential\n\n\n\n\n\n\n\nlife\n\n\noutlier\n\n\n\n\nIt’s a tragedy when those who have talent don’t get to fully express it because of the environment.\n\n\n\n\n\n\nMar 12, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWar\n\n\n\n\n\n\n\nlife\n\n\n\n\nWhat good is in a war?\n\n\n\n\n\n\nMar 6, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimulate: proof of concept R-package\n\n\n\n\n\n\n\nR\n\n\nsimulate\n\n\n\n\nA proof of concept of parametric simulation framework to generate complex multivariate and multilevel data\n\n\n\n\n\n\nFeb 24, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColorblind checks for qualitative palettes\n\n\n\n\n\n\n\nR\n\n\ncolor\n\n\n\n\nChecking the color blind friendliness of a number of qualitative palettes.\n\n\n\n\n\n\nFeb 20, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n  \n\n\n\n\nManipulating arrays with dynamic dimensions in R\n\n\n\n\n\n\n\nR\n\n\nprogramming\n\n\n\n\nChallenges and solutions for creating functions to manipulate arrays in R when the number of dimensions is unknown.\n\n\n\n\n\n\nJan 18, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n  \n\n\n\n\nAre anime titles getting longer?\n\n\n\n\n\n\n\nanime\n\n\nR\n\n\n\n\nA quick exploratory analysis on the length of anime titles.\n\n\n\n\n\n\nJan 16, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre anime titles getting longer?\n\n\n\n\n\n\n\nanime\n\n\nR\n\n\n\n\nA quick exploratory analysis on the length of anime titles.\n\n\n\n\n\n\nJan 16, 2022\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrent state of R packages for the design of experiments\n\n\n\n\n\n\n\nexperimental design\n\n\nR\n\n\n\n\nYour analytical toolkit matters very little if the data are no good. Ideally you want to know to how the data were collected before delving into the analysis of the data; better yet, get involved before the collection of data and design its collection. In this post I explore some of the top downloaded R packages for the design of experiments and analysis of experimental data.\n\n\n\n\n\n\nFeb 3, 2021\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrawing a UML Sequence Diagram\n\n\n\n\n\n\n\nvisualisation\n\n\ndiagram\n\n\n\n\nSearch for the way to draw a UML sequence diagram.\n\n\n\n\n\n\nJan 29, 2021\n\n\nEmi Tanaka\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Travel Schedule 2019: Building an interactive visualisation as twitter card\n\n\n\n\n\n\n\nvisualisation\n\n\ninteractive\n\n\n\n\nMaking an interactive schedule heat map with interactive twitter card display.\n\n\n\n\n\n\nMar 26, 2019\n\n\nEmi Tanaka\n\n\n\n\n\n\n  \n\n\n\n\nMaking a Hexagon Sticker\n\n\n\n\n\n\n\nfun\n\n\n\n\nMaking hexagon stickers have become popular for R-packages with the range of packages associated with RStudio, such as ggplot2, knitr, devtools and so on, having its own hex stickers. For the sticker that I made for my R-package I found it easier, partly due to its long name, to use powerpoint to manipulate the image and create a semi-circular text.\n\n\n\n\n\n\nApr 6, 2018\n\n\nEmi Tanaka\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#experimental-data",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#experimental-data",
    "title": "Current state of R packages for the design of experiments",
    "section": "Experimental data",
    "text": "Experimental data\nAll experiments are conducted with some objective in mind. This could be that a scientist may wish to test their hypothesis, a manufacturer wants to know which manufacturing process is better or a researcher wants to understand some cause-and-effect relationships. A characteristic part of an experiment is that the experimenter has control over some explanatory variables. In a comparative experiment, the control is over the allocation of treatments to subjects. Designing an experiment in the statistics discipline usually focus on this allocation, although it’s important to keep in mind that there are other decision factors in an experiment.\nData that are collected from experiments are what we refer to as experimental data. Because it was collected with some objective in mind followed by some data collection plan, experimental data are often thought of to be better quality than observational data. But then again if you can’t quantify the quality of data, you can’t really tell. Certain scientific claims (e.g. causation, better treatment) can only be substantiated by experiments and so experimental data is held to a higher standard in general."
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#bigram-of-doe-package-titles-and-descriptions",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#bigram-of-doe-package-titles-and-descriptions",
    "title": "Current state of R packages for the design of experiments",
    "section": "Bigram of DoE package titles and descriptions",
    "text": "Bigram of DoE package titles and descriptions\n\n\nstop_words_ext <- c(stop_words$word, \"doi\")\n\ndoe_db <- db %>% \n  filter(Package %in% doe_pkgs) %>% \n  mutate(Description = str_replace_all(Description, \"\\n\", \" \"),\n         Description = str_squish(Description),\n         Title = str_replace_all(Title, \"\\n\", \" \"))\n\nbigram_tab <- function(data, col) {\n  data %>% \n    unnest_tokens(word, {{col}}, token = \"ngrams\", n = 2) %>% \n    separate(word, c(\"word1\", \"word2\"), sep = \" \") %>% \n    mutate(word1 = singularize(word1),\n           word2 = singularize(word2)) %>% \n    # don't count the same bigram within the same package\n    distinct(Package, word1, word2) %>% \n    filter(!word1 %in% stop_words_ext,\n           !word2 %in% stop_words_ext,\n           !str_detect(word1, \"^[0-9.]+$\"),\n           !str_detect(word2, \"^[0-9.]+$\")) %>% \n    count(word1, word2, sort = TRUE)  \n}\n\n\n\n\nbigram_tab(doe_db, Description) %>% \n  filter(n > 4) %>% \n  mutate(word = paste(word1, word2)) %>% \n  select(word, n) %>% \n  kbl(caption = \"The bigram of the R-package _descriptions_ as provided in the DESCRIPTION file in CRAN.\", \n               col.names = c(\"Bigram\", \"Count\")) %>% \n  kable_classic(full_width = FALSE)\n\n\n\n\nbigram_tab(doe_db, Title) %>% \n  filter(n > 3) %>% \n  mutate(word = paste(word1, word2)) %>% \n  select(word, n) %>% \n  kbl(caption = \"The bigram of the R-package _titles_ as provided in the DESCRIPTION file in CRAN.\", \n               col.names = c(\"Bigram\", \"Count\")) %>% \n  kable_classic(full_width = FALSE)\n\n\nTable @ref(tab:bigram-title) shows the most common bigrams in the title of the DoE packages. It’s perhaps not surprising but the words “optimal design” and “experimental design” are the top. It’s also likely that the words “design of experiments” appears often but because this is a bigram (two consecutive words) so it doesn’t appear. You might then wonder if that’s the case words like “design of” or “of experiments” should make an appearance, however “of” is a stop word and these are filtered out otherwise unwanted bigrams come up on the top.\nThere are couple of words like “clinical trial” and “dose finding” that suggests applications in medical experiments, as well as “microarray experiment” that suggests application in bioinformatics.\n\n\n\n\nThe bigram of the R-package _titles_ as provided in the DESCRIPTION file in CRAN.\n \n  \n    Bigram \n    Count \n  \n \n\n  \n    experimental design \n    6 \n  \n  \n    optimal design \n    6 \n  \n  \n    clinical trial \n    5 \n  \n  \n    dose finding \n    5 \n  \n  \n    sequential design \n    5 \n  \n  \n    block design \n    4 \n  \n  \n    microarray experiment \n    4 \n  \n\n\n\n\n\nThe title alone might be too succinct for text analysis so I also had a look at the most common bigrams in the description of the DoE packages as shown in Table @ref(tab:bigram-desc). The counts in Table @ref(tab:bigram-desc) (and also Table @ref(tab:bigram-title)) is across the DoE packages. To be more clear, even if the bigram is mentioned multiple times within the description, it’s only counted once per package. This removes the inflation of the counts due to one package mentioning the same bigram over and over again.\nAgain not surprisingly “experimental design” and “optimal design” comes on top in the DoE package descriptions. The words “graphical user” and “user interface” implies that the trigram “graphical user interface” was probably common.\n\n\n\n\nThe bigram of the R-package _descriptions_ as provided in the DESCRIPTION file in CRAN.\n \n  \n    Bigram \n    Count \n  \n \n\n  \n    experimental design \n    7 \n  \n  \n    optimal design \n    7 \n  \n  \n    block design \n    5 \n  \n  \n    clinical trial \n    5 \n  \n  \n    factorial design \n    5 \n  \n  \n    graphical user \n    5 \n  \n  \n    microarray experiment \n    5 \n  \n  \n    user interface \n    5"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#network-of-doe-package-imports-and-dependencies",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#network-of-doe-package-imports-and-dependencies",
    "title": "Current state of R packages for the design of experiments",
    "section": "Network of DoE package imports and dependencies",
    "text": "Network of DoE package imports and dependencies\n\n\ndoe_imports <- doe_db %>% \n  mutate(Depends = str_replace_all(Depends, \"\\n\", \" \"),\n         Depends = str_replace_all(Depends, fixed(\"(\"), \" (\"),\n         Imports = str_replace_all(Imports, \"\\n\", \" \"),\n         Imports = str_replace_all(Imports, fixed(\"(\"), \" (\"),\n         imports = str_c(Depends, Imports, sep = \",\"),\n         imports = str_split(imports, \",\"),\n         imports = map(imports, ~{\n                    str_squish(.x) %>% \n                      word() %>% \n                      .[.!=\"\"]}\n           ),\n         imports_doe = map(imports, ~.x[.x %in% doe_pkgs])) %>% \n  select(Package, imports_doe) %>% \n  unnest_longer(imports_doe) %>% \n  filter(!is.na(imports_doe)) %>% \n  rename(from = imports_doe, to = Package) %>% \n  select(from, to)\n\n\nFigure @ref(fig:doe-network) shows the imports and dependency between the DoE packages. We can see here that DoE.wrapper imports a fair number of DoE packages that results in the major network cluster see in Figure @ref(fig:doe-network). AlgDesign and DoE.base are imported into four other DoE packages so form an important base in the DoE world.\n\n\ngraph_from_data_frame(doe_imports) %>% \n  ggraph(layout = 'fr') +\n  geom_edge_link(aes(start_cap = label_rect(node1.name),\n                     end_cap = label_rect(node2.name)), \n                 arrow = arrow(length = unit(2, 'mm')),\n                 color = \"#79003e\") + \n  geom_node_text(aes(label = name),\n                 color = \"#79003e\") +\n  theme(panel.background = element_rect(fill = \"#f6e5ee\",\n                                        color = \"#79003e\"),\n        plot.margin = margin(20, 20, 20, 20))\n\n\n(ref:network) The network of imports and dependency among DoE packages alone. Each node represents a DoE package. DoE packages with no imports or dependency on other DoE packages are excluded. Each arrow represents the relationship between the packages such that the package on the tail is used by package on the head of the arrow.\n\n\n\n\n\n(ref:network)"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#cran-download-logs",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#cran-download-logs",
    "title": "Current state of R packages for the design of experiments",
    "section": "CRAN download logs",
    "text": "CRAN download logs\n\n\nend <- Sys.Date() - 2 # usually 1-2 days are not available yet\nstart <- end - years(5) + days(2)\ndldat <- cran_downloads(doe_pkgs, from = start, to = end)\n\n\n\n\ndldat %>% \n    group_by(package) %>% \n    summarise(total = sum(count)) %>%\n  ggplot(aes(total)) + \n  geom_histogram(color = \"white\", fill = \"#AD0059\") + \n  scale_x_log10(label = comma) + \n  myggtheme + \n  labs(x = glue(\"Total download counts from {start} to {end}\"),\n       y = \"Number of packages\") +\n  scale_y_continuous(expand = c(0, 0))\n\n\nFigure @ref(fig:download-hist) shows the distribution of the total download counts over the last 5 years4 of the DoE packages. This graph doesn’t take into account that some DoE packages may only have been on CRAN in the last 5 years so the counts are in favour of DoE packages that’s been on CRAN longer.\n(ref:hist) Histogram of the total download count over last 5 years of the DoE packages.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n(ref:hist)"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#top-5-doe-packages",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#top-5-doe-packages",
    "title": "Current state of R packages for the design of experiments",
    "section": "Top 5 DoE packages",
    "text": "Top 5 DoE packages\n\n\nntop <- 5\n\ntop5sum_df <- dldat %>% \n  group_by(package) %>% \n  summarise(total = sum(count)) %>% \n  ungroup() %>% \n  slice_max(order_by = total, n = ntop)\n\ntop5 <- top5sum_df %>% \n  pull(package) \n\ntop5_df <- dldat %>% \n  filter(package %in% top5) %>% \n  mutate(package = fct_reorder(package, count, function(x) -sum(x))) \n\n\nThe top 5 downloaded DoE packages at the time of this writing are AlgDesign, lhs, DiceDesign, DoE.base, and FrF2. You can see the download counts in Figure @ref(fig:download-barplot).\n\n\ntop5sum_df %>% \n  mutate(package = fct_reorder(package, total)) %>% \n  ggplot(aes(total, package)) +\n  geom_col(aes(fill = package)) +\n  labs(x = glue(\"Total downloads from {start} to {end}\"),\n       y = \"Package\") + \n  scale_x_continuous(labels = comma, expand = c(0, 0)) +\n  myggtheme + \n  scale_fill_discrete_qualitative(rev = TRUE) + \n  guides(fill = FALSE)\n\n\n(ref:barplot) The above barplot shows the total downloads of the top 5 downloaded DoE packages from the period 2017-09-18 to 2022-09-16.\n\n\nWarning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n\"none\")` instead.\n\n\n\n\n\n(ref:barplot)\n\n\n\n\nWe can have a look at further examination of the top 5 DoE packages by looking at the daily download counts as shown in Figure @ref(fig:download-barplot). The download counts are the raw values and these include downloads by CRAN mirror and bots. There is a noticeable spike when there is an update to the CRAN package. This is partly because when there is a new version of the package, when you install other packages that depend or import it then R will prompt you to install the new version. This means that the download counts are inflated and to some extent you can artificially boost them by making regular CRAN updates. The adjustedcranlogs (Morgan-Wall 2017) makes a nice attempt to adjust the raw counts based on a certain heuristic. I didn’t use it since the adjustment is stochastic and I appear to have hit a bug.\n\n\npkg_url <- \"https://cran.r-project.org/web/packages/{pkg}/index.html\"\npkg_archive <- \"https://cran.r-project.org/src/contrib/Archive/{pkg}/\"\npkg_updates <- map(top5, function(pkg) {\n    last_update <- read_html(glue(pkg_url)) %>% \n      html_table() %>% \n      .[[1]] %>% \n      filter(X1==\"Published:\") %>% \n      pull(X2) %>% \n      ymd()\n      \n    archive_dates <- tryCatch({ \n        read_html(glue(pkg_archive)) %>% \n          html_table() %>%\n          .[[1]] %>% \n          pull(`Last modified`) %>% \n          ymd_hm() %>% \n          na.omit() %>% \n          as.Date()\n      }, error = function(e) {\n        NULL\n      })\n    c(archive_dates, last_update)\n  })\nnames(pkg_updates) <- top5\n\nupdates <- unlist(pkg_updates) %>% \n  enframe(\"package\", \"update\") %>% \n  # unlist converts date to integers\n  mutate(update = as.Date(update, origin = \"1970-01-01\"),\n         # need to get rid of the numbers appended to pkg names\n         package = str_extract(package, paste0(top5, collapse=\"|\")),\n         package = factor(package, levels = top5)) %>% \n  filter(between(update, start, end))\n\n\n\n\nggplot(top5_df, aes(date, count, color = package)) +\n  # add shadow lines\n  geom_line(data = rename(top5_df, package2 = package), \n            color = \"gray\", aes(group = package2)) +\n  # add date when package was updated\n  geom_vline(data = updates, aes(xintercept = update),\n             linetype = \"dashed\", color = \"#79003e\") + \n  # the trend line\n  geom_line() +\n  scale_y_log10() +\n  facet_grid(package ~ .) + \n  labs(title = glue(\"Top 5 downloaded DoE packages from {start} to {end}\")) + \n  scale_color_discrete_qualitative() +\n  guides(color = FALSE) +\n  myggtheme\n\n\n(ref:timeplot) The above plot shows the daily downloads of the top 5 downloaded DoE packages from the period 2017-09-18 to 2022-09-16. The vertical dotted bar corresponds to the date that a new version of the corresponding package was released on CRAN.\n\n\nWarning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n\"none\")` instead.\n\n\n\n\n\n(ref:timeplot)"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#algdesign",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#algdesign",
    "title": "Current state of R packages for the design of experiments",
    "section": "AlgDesign",
    "text": "AlgDesign\nTo start off, we begin with the most downloaded DoE package, AlgDesign. The examples below are taken directly from the vignette of the AlgDesign package.\n\nlibrary(AlgDesign)\n\nYou can create a balanced incomplete block design using the optBlock function. It’s using an optimal design framework where the default criterion is D criterion and the implied model is given in the first argument.\n\nBIB <- optBlock(~ ., \n                withinData = factor(1:7), \n                blocksize = rep(3, 7))\nBIB\n\n$D\n[1] 0.08033556\n\n$diagonality\n[1] 0.692\n\n$Blocks\n$Blocks$B1\n  X1\n1  1\n3  3\n4  4\n\n$Blocks$B2\n  X1\n2  2\n4  4\n5  5\n\n$Blocks$B3\n  X1\n4  4\n6  6\n7  7\n\n$Blocks$B4\n  X1\n3  3\n5  5\n6  6\n\n$Blocks$B5\n  X1\n2  2\n3  3\n7  7\n\n$Blocks$B6\n  X1\n1  1\n2  2\n6  6\n\n$Blocks$B7\n  X1\n1  1\n5  5\n7  7\n\n\n$design\n   X1\n1   1\n3   3\n4   4\n2   2\n41  4\n5   5\n42  4\n6   6\n7   7\n31  3\n51  5\n61  6\n21  2\n32  3\n71  7\n11  1\n22  2\n62  6\n12  1\n52  5\n72  7\n\n$rows\n [1] 1 3 4 2 4 5 4 6 7 3 5 6 2 3 7 1 2 6 1 5 7\n\n\nAlgDesign also includes helper functions to generate a factorial structure.\n\ndat <- gen.factorial(2, 7)\ndat\n\n    X1 X2 X3 X4 X5 X6 X7\n1   -1 -1 -1 -1 -1 -1 -1\n2    1 -1 -1 -1 -1 -1 -1\n3   -1  1 -1 -1 -1 -1 -1\n4    1  1 -1 -1 -1 -1 -1\n5   -1 -1  1 -1 -1 -1 -1\n6    1 -1  1 -1 -1 -1 -1\n7   -1  1  1 -1 -1 -1 -1\n8    1  1  1 -1 -1 -1 -1\n9   -1 -1 -1  1 -1 -1 -1\n10   1 -1 -1  1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n12   1  1 -1  1 -1 -1 -1\n13  -1 -1  1  1 -1 -1 -1\n14   1 -1  1  1 -1 -1 -1\n15  -1  1  1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n18   1 -1 -1 -1  1 -1 -1\n19  -1  1 -1 -1  1 -1 -1\n20   1  1 -1 -1  1 -1 -1\n21  -1 -1  1 -1  1 -1 -1\n22   1 -1  1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n24   1  1  1 -1  1 -1 -1\n25  -1 -1 -1  1  1 -1 -1\n26   1 -1 -1  1  1 -1 -1\n27  -1  1 -1  1  1 -1 -1\n28   1  1 -1  1  1 -1 -1\n29  -1 -1  1  1  1 -1 -1\n30   1 -1  1  1  1 -1 -1\n31  -1  1  1  1  1 -1 -1\n32   1  1  1  1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n34   1 -1 -1 -1 -1  1 -1\n35  -1  1 -1 -1 -1  1 -1\n36   1  1 -1 -1 -1  1 -1\n37  -1 -1  1 -1 -1  1 -1\n38   1 -1  1 -1 -1  1 -1\n39  -1  1  1 -1 -1  1 -1\n40   1  1  1 -1 -1  1 -1\n41  -1 -1 -1  1 -1  1 -1\n42   1 -1 -1  1 -1  1 -1\n43  -1  1 -1  1 -1  1 -1\n44   1  1 -1  1 -1  1 -1\n45  -1 -1  1  1 -1  1 -1\n46   1 -1  1  1 -1  1 -1\n47  -1  1  1  1 -1  1 -1\n48   1  1  1  1 -1  1 -1\n49  -1 -1 -1 -1  1  1 -1\n50   1 -1 -1 -1  1  1 -1\n51  -1  1 -1 -1  1  1 -1\n52   1  1 -1 -1  1  1 -1\n53  -1 -1  1 -1  1  1 -1\n54   1 -1  1 -1  1  1 -1\n55  -1  1  1 -1  1  1 -1\n56   1  1  1 -1  1  1 -1\n57  -1 -1 -1  1  1  1 -1\n58   1 -1 -1  1  1  1 -1\n59  -1  1 -1  1  1  1 -1\n60   1  1 -1  1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n62   1 -1  1  1  1  1 -1\n63  -1  1  1  1  1  1 -1\n64   1  1  1  1  1  1 -1\n65  -1 -1 -1 -1 -1 -1  1\n66   1 -1 -1 -1 -1 -1  1\n67  -1  1 -1 -1 -1 -1  1\n68   1  1 -1 -1 -1 -1  1\n69  -1 -1  1 -1 -1 -1  1\n70   1 -1  1 -1 -1 -1  1\n71  -1  1  1 -1 -1 -1  1\n72   1  1  1 -1 -1 -1  1\n73  -1 -1 -1  1 -1 -1  1\n74   1 -1 -1  1 -1 -1  1\n75  -1  1 -1  1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n77  -1 -1  1  1 -1 -1  1\n78   1 -1  1  1 -1 -1  1\n79  -1  1  1  1 -1 -1  1\n80   1  1  1  1 -1 -1  1\n81  -1 -1 -1 -1  1 -1  1\n82   1 -1 -1 -1  1 -1  1\n83  -1  1 -1 -1  1 -1  1\n84   1  1 -1 -1  1 -1  1\n85  -1 -1  1 -1  1 -1  1\n86   1 -1  1 -1  1 -1  1\n87  -1  1  1 -1  1 -1  1\n88   1  1  1 -1  1 -1  1\n89  -1 -1 -1  1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n91  -1  1 -1  1  1 -1  1\n92   1  1 -1  1  1 -1  1\n93  -1 -1  1  1  1 -1  1\n94   1 -1  1  1  1 -1  1\n95  -1  1  1  1  1 -1  1\n96   1  1  1  1  1 -1  1\n97  -1 -1 -1 -1 -1  1  1\n98   1 -1 -1 -1 -1  1  1\n99  -1  1 -1 -1 -1  1  1\n100  1  1 -1 -1 -1  1  1\n101 -1 -1  1 -1 -1  1  1\n102  1 -1  1 -1 -1  1  1\n103 -1  1  1 -1 -1  1  1\n104  1  1  1 -1 -1  1  1\n105 -1 -1 -1  1 -1  1  1\n106  1 -1 -1  1 -1  1  1\n107 -1  1 -1  1 -1  1  1\n108  1  1 -1  1 -1  1  1\n109 -1 -1  1  1 -1  1  1\n110  1 -1  1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n112  1  1  1  1 -1  1  1\n113 -1 -1 -1 -1  1  1  1\n114  1 -1 -1 -1  1  1  1\n115 -1  1 -1 -1  1  1  1\n116  1  1 -1 -1  1  1  1\n117 -1 -1  1 -1  1  1  1\n118  1 -1  1 -1  1  1  1\n119 -1  1  1 -1  1  1  1\n120  1  1  1 -1  1  1  1\n121 -1 -1 -1  1  1  1  1\n122  1 -1 -1  1  1  1  1\n123 -1  1 -1  1  1  1  1\n124  1  1 -1  1  1  1  1\n125 -1 -1  1  1  1  1  1\n126  1 -1  1  1  1  1  1\n127 -1  1  1  1  1  1  1\n128  1  1  1  1  1  1  1\n\n\nThis can be an input to specify the design using another function, say with optFederov which uses Federov’s exchange algorithm to generate the design.\n\ndesF <- optFederov(~ .^2, \n                   data = dat,\n                   nTrials = 32,\n                   nRepeats = 100)\ndesF\n\n$D\n[1] 0.8867999\n\n$A\n[1] 1.296784\n\n$Ge\n[1] 0.412\n\n$Dea\n[1] 0.241\n\n$design\n    X1 X2 X3 X4 X5 X6 X7\n4    1  1 -1 -1 -1 -1 -1\n5   -1 -1  1 -1 -1 -1 -1\n10   1 -1 -1  1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n28   1  1 -1  1  1 -1 -1\n30   1 -1  1  1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n38   1 -1  1 -1 -1  1 -1\n44   1  1 -1  1 -1  1 -1\n50   1 -1 -1 -1  1  1 -1\n51  -1  1 -1 -1  1  1 -1\n56   1  1  1 -1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n66   1 -1 -1 -1 -1 -1  1\n67  -1  1 -1 -1 -1 -1  1\n72   1  1  1 -1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n77  -1 -1  1  1 -1 -1  1\n84   1  1 -1 -1  1 -1  1\n86   1 -1  1 -1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n95  -1  1  1  1  1 -1  1\n100  1  1 -1 -1 -1  1  1\n105 -1 -1 -1  1 -1  1  1\n110  1 -1  1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n117 -1 -1  1 -1  1  1  1\n123 -1  1 -1  1  1  1  1\n128  1  1  1  1  1  1  1\n\n$rows\n [1]   4   5  10  11  16  17  23  28  30  33  38  44  50  51  56  61  66  67  72\n[20]  76  77  84  86  90  95 100 105 110 111 117 123 128\n\n\nIf you want to further randomise within blocks, you can pass the above result to optBlock.\n\ndesFBlk <- optBlock(~ .^2, \n                    withinData = desF$design,\n                    blocksizes = rep(8, 4),\n                    nRepeats = 20)\n\ndesFBlk\n\n$D\n[1] 0.8049815\n\n$diagonality\n[1] 0.836\n\n$Blocks\n$Blocks$B1\n    X1 X2 X3 X4 X5 X6 X7\n4    1  1 -1 -1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n77  -1 -1  1  1 -1 -1  1\n84   1  1 -1 -1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n123 -1  1 -1  1  1  1  1\n\n$Blocks$B2\n    X1 X2 X3 X4 X5 X6 X7\n10   1 -1 -1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n28   1  1 -1  1  1 -1 -1\n50   1 -1 -1 -1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n67  -1  1 -1 -1 -1 -1  1\n86   1 -1  1 -1  1 -1  1\n100  1  1 -1 -1 -1  1  1\n\n$Blocks$B3\n    X1 X2 X3 X4 X5 X6 X7\n5   -1 -1  1 -1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n30   1 -1  1  1  1 -1 -1\n44   1  1 -1  1 -1  1 -1\n56   1  1  1 -1  1  1 -1\n66   1 -1 -1 -1 -1 -1  1\n95  -1  1  1  1  1 -1  1\n110  1 -1  1  1 -1  1  1\n\n$Blocks$B4\n    X1 X2 X3 X4 X5 X6 X7\n38   1 -1  1 -1 -1  1 -1\n51  -1  1 -1 -1  1  1 -1\n72   1  1  1 -1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n105 -1 -1 -1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n117 -1 -1  1 -1  1  1  1\n128  1  1  1  1  1  1  1\n\n\n$design\n    X1 X2 X3 X4 X5 X6 X7\n4    1  1 -1 -1 -1 -1 -1\n17  -1 -1 -1 -1  1 -1 -1\n23  -1  1  1 -1  1 -1 -1\n33  -1 -1 -1 -1 -1  1 -1\n77  -1 -1  1  1 -1 -1  1\n84   1  1 -1 -1  1 -1  1\n90   1 -1 -1  1  1 -1  1\n123 -1  1 -1  1  1  1  1\n10   1 -1 -1  1 -1 -1 -1\n16   1  1  1  1 -1 -1 -1\n28   1  1 -1  1  1 -1 -1\n50   1 -1 -1 -1  1  1 -1\n61  -1 -1  1  1  1  1 -1\n67  -1  1 -1 -1 -1 -1  1\n86   1 -1  1 -1  1 -1  1\n100  1  1 -1 -1 -1  1  1\n5   -1 -1  1 -1 -1 -1 -1\n11  -1  1 -1  1 -1 -1 -1\n30   1 -1  1  1  1 -1 -1\n44   1  1 -1  1 -1  1 -1\n56   1  1  1 -1  1  1 -1\n66   1 -1 -1 -1 -1 -1  1\n95  -1  1  1  1  1 -1  1\n110  1 -1  1  1 -1  1  1\n38   1 -1  1 -1 -1  1 -1\n51  -1  1 -1 -1  1  1 -1\n72   1  1  1 -1 -1 -1  1\n76   1  1 -1  1 -1 -1  1\n105 -1 -1 -1  1 -1  1  1\n111 -1  1  1  1 -1  1  1\n117 -1 -1  1 -1  1  1  1\n128  1  1  1  1  1  1  1\n\n$rows\n [1]   4  17  23  33  77  84  90 123  10  16  28  50  61  67  86 100   5  11  30\n[20]  44  56  66  95 110  38  51  72  76 105 111 117 128"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#agricolae",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#agricolae",
    "title": "Current state of R packages for the design of experiments",
    "section": "agricolae",
    "text": "agricolae\nagricolae is motivated by agricultural applications although the designs are applicable across a variety of fields.\n\nlibrary(agricolae)\n\n\nAttaching package: 'agricolae'\n\n\nThe following object is masked from 'package:igraph':\n\n    similarity\n\n\nThe functions to create the design all begin with the word “design.” and the names of the functions are remnant of the name of the experimental design. E.g. design.rcbd generates a Randomised Complete Block Design and design.split generates a Split Plot Design.\n\nls(\"package:agricolae\") %>% \n  str_subset(\"^design.\")\n\n [1] \"design.ab\"      \"design.alpha\"   \"design.bib\"     \"design.crd\"    \n [5] \"design.cyclic\"  \"design.dau\"     \"design.graeco\"  \"design.lattice\"\n [9] \"design.lsd\"     \"design.mat\"     \"design.rcbd\"    \"design.split\"  \n[13] \"design.strip\"   \"design.youden\" \n\n\nRather than going through each of the functions, I’ll just show one. The command below generates a balanced incomplete block design with 7 treatments of block size 3. This the same design structure as the first example for AlgDesign. What do you think of the input and output?\n\ntrt <- LETTERS[1:7]\ndesign.bib(trt = trt, k = 3)\n\n\nParameters BIB\n==============\nLambda     : 1\ntreatmeans : 7\nBlock size : 3\nBlocks     : 7\nReplication: 3 \n\nEfficiency factor 0.7777778 \n\n<<< Book >>>\n\n\n$parameters\n$parameters$design\n[1] \"bib\"\n\n$parameters$trt\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\"\n\n$parameters$k\n[1] 3\n\n$parameters$serie\n[1] 2\n\n$parameters$seed\n[1] 1804898417\n\n$parameters$kinds\n[1] \"Super-Duper\"\n\n\n$statistics\n       lambda treatmeans blockSize blocks r Efficiency\nvalues      1          7         3      7 3  0.7777778\n\n$sketch\n     [,1] [,2] [,3]\n[1,] \"C\"  \"B\"  \"D\" \n[2,] \"A\"  \"E\"  \"B\" \n[3,] \"F\"  \"B\"  \"G\" \n[4,] \"G\"  \"C\"  \"E\" \n[5,] \"G\"  \"A\"  \"D\" \n[6,] \"A\"  \"F\"  \"C\" \n[7,] \"F\"  \"E\"  \"D\" \n\n$book\n   plots block trt\n1    101     1   C\n2    102     1   B\n3    103     1   D\n4    201     2   A\n5    202     2   E\n6    203     2   B\n7    301     3   F\n8    302     3   B\n9    303     3   G\n10   401     4   G\n11   402     4   C\n12   403     4   E\n13   501     5   G\n14   502     5   A\n15   503     5   D\n16   601     6   A\n17   602     6   F\n18   603     6   C\n19   701     7   F\n20   702     7   E\n21   703     7   D\n\n\nMore examples are given in the agricolae tutorial."
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#lhs",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#lhs",
    "title": "Current state of R packages for the design of experiments",
    "section": "lhs",
    "text": "lhs\nThe lhs package is completely different to the previous two packages. It implements methods for creating and augmenting Latin Hypercube Samples and Orthogonal Array Latin Hypercube Samples. The treatment variables here are the parameters and are continuous. In the example below, there are 10 parameters were 30 samples will be drawn from.\n\nlibrary(lhs)\n# a design with 30 samples from 10 parameters\nA <- randomLHS(30, 10)\nA\n\n            [,1]       [,2]       [,3]       [,4]        [,5]       [,6]\n [1,] 0.85115160 0.80153721 0.26562089 0.24240381 0.386617133 0.57523291\n [2,] 0.03162770 0.11851068 0.20750833 0.22137816 0.737580563 0.37572590\n [3,] 0.94326309 0.99286802 0.55167951 0.04431126 0.073908842 0.33729208\n [4,] 0.15341898 0.23664814 0.45088836 0.02736497 0.276594703 0.77521524\n [5,] 0.53987796 0.69129259 0.61068716 0.68112190 0.840092421 0.18545904\n [6,] 0.34338962 0.91067411 0.50772141 0.46340514 0.543650700 0.04848456\n [7,] 0.87984431 0.18530938 0.28391957 0.80767211 0.636091307 0.40499358\n [8,] 0.74093451 0.94142899 0.47633881 0.93482745 0.101815507 0.83195048\n [9,] 0.22679294 0.05950478 0.70384589 0.84840308 0.046119869 0.20549016\n[10,] 0.59543890 0.14230001 0.91973016 0.38743743 0.008173053 0.11180544\n[11,] 0.71222052 0.84574251 0.05719443 0.33460392 0.414795358 0.71230339\n[12,] 0.31313954 0.55023270 0.67189798 0.98743475 0.480147544 0.14900939\n[13,] 0.06589897 0.02727366 0.94372045 0.11200430 0.776188787 0.31845634\n[14,] 0.67856942 0.64694630 0.11695731 0.57667893 0.576669680 0.68236586\n[15,] 0.60779222 0.47346774 0.57803451 0.77359785 0.686925390 0.46043188\n[16,] 0.77869112 0.45967726 0.97082607 0.72001527 0.158727598 0.52748006\n[17,] 0.47753672 0.33965295 0.34264293 0.88078583 0.932636317 0.08469157\n[18,] 0.24829930 0.28054142 0.82863690 0.48987801 0.831406425 0.28007202\n[19,] 0.63438918 0.62665931 0.19339855 0.63126047 0.222550404 0.84219677\n[20,] 0.42615936 0.78697269 0.31122846 0.54731724 0.618925200 0.98370876\n[21,] 0.98558294 0.31283813 0.79937608 0.09708168 0.974254219 0.48614679\n[22,] 0.82272308 0.72620385 0.63409490 0.51439160 0.888309555 0.94892286\n[23,] 0.28216288 0.40678670 0.00747647 0.15786391 0.462001814 0.89070787\n[24,] 0.44293885 0.88759165 0.87593133 0.17614748 0.301809115 0.03273681\n[25,] 0.91903885 0.58769320 0.85344414 0.73340894 0.261399107 0.65831637\n[26,] 0.39749211 0.21531852 0.40155710 0.40795272 0.175926862 0.54073941\n[27,] 0.53326444 0.09494134 0.36906730 0.28462433 0.521423827 0.62613184\n[28,] 0.12780125 0.76041647 0.14450865 0.32753635 0.958334555 0.25256769\n[29,] 0.19956924 0.39260007 0.76646006 0.65147638 0.353769748 0.90342254\n[30,] 0.09115621 0.53145384 0.09544316 0.91317843 0.722981039 0.74109078\n            [,7]       [,8]       [,9]      [,10]\n [1,] 0.64829514 0.30957145 0.56063376 0.58060694\n [2,] 0.09386871 0.09460784 0.62699580 0.07496677\n [3,] 0.14971910 0.02306924 0.12609065 0.18310414\n [4,] 0.27273750 0.43275425 0.84548534 0.13991032\n [5,] 0.57024842 0.83876578 0.94430739 0.55675175\n [6,] 0.68468958 0.93462688 0.69388363 0.77296080\n [7,] 0.22736413 0.49914901 0.63951785 0.29475412\n [8,] 0.86262149 0.90864828 0.71549074 0.95154810\n [9,] 0.82450164 0.34137614 0.35590469 0.33383492\n[10,] 0.99755568 0.77506400 0.90850387 0.04070513\n[11,] 0.51386141 0.51188486 0.74575618 0.47042600\n[12,] 0.62716610 0.60853776 0.19349115 0.85808318\n[13,] 0.36810057 0.68906398 0.48416759 0.10075997\n[14,] 0.46367072 0.53735362 0.97946521 0.53084746\n[15,] 0.79151449 0.39841726 0.16295411 0.32738380\n[16,] 0.73055037 0.10636268 0.45184454 0.60852297\n[17,] 0.11492100 0.64512714 0.26197028 0.87144705\n[18,] 0.90350371 0.27696270 0.41905694 0.25261507\n[19,] 0.41560144 0.73423244 0.01653787 0.01640204\n[20,] 0.54984313 0.26617569 0.32944947 0.20285318\n[21,] 0.73515250 0.59964083 0.87721937 0.82147435\n[22,] 0.89461948 0.05944528 0.27581653 0.97355201\n[23,] 0.95209334 0.17557806 0.57880924 0.65490041\n[24,] 0.35714952 0.82135876 0.80705301 0.91792197\n[25,] 0.31657015 0.44139011 0.39117389 0.72964052\n[26,] 0.03568867 0.88231315 0.53096409 0.45227701\n[27,] 0.18195056 0.23326926 0.79716759 0.42737304\n[28,] 0.48629095 0.72335715 0.07429013 0.67936824\n[29,] 0.03184096 0.15672156 0.06023826 0.73960757\n[30,] 0.23509647 0.98392432 0.20423196 0.38968498\n\n\nlhs provides a number of methods to find the optimal design each with their own criteria.\n\nA1 <- optimumLHS(30, 10, maxSweeps = 4, eps = 0.01)\nA2 <- maximinLHS(30, 10, dup = 5)\nA3 <- improvedLHS(30, 10, dup = 5)\nA4 <- geneticLHS(30, 10, pop = 1000, gen = 8, pMut = 0.1, criterium = \"S\")\nA5 <- geneticLHS(30, 10, pop = 1000, gen = 8, pMut = 0.1, criterium = \"Maximin\")"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#ez",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#ez",
    "title": "Current state of R packages for the design of experiments",
    "section": "ez",
    "text": "ez\nThis is mainly focussed on the analysis of experimental data but some functions such as ezDesign is useful for viewing the experimental structure.\n\nlibrary(ez)\ndata(ANT2)\nezPrecis(ANT2)\n\nData frame dimensions: 5760 rows, 10 columns\n\n\n             type missing values      min         max\nsubnum    numeric       0     20        1          20\ngroup      factor       0      2  Control   Treatment\nblock     numeric       0      6        1           6\ntrial      factor       0     48        1          48\ncue        factor       0      4     None     Spatial\nflank      factor       0      3  Neutral Incongruent\nlocation   factor       0      2     down          up\ndirection  factor       0      2     left       right\nrt        numeric     144   5617 179.5972    657.6986\nerror     numeric     144      3        0           1\n\n\n\nezDesign(data = ANT2,\n         x = trial, \n         y = subnum,\n         row = block, \n         col = group)"
  },
  {
    "objectID": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#doe.base",
    "href": "blog/2021-02-03-current-state-of-experimental-design-r-packages/current-state-of-experimental-design-r-packages.html#doe.base",
    "title": "Current state of R packages for the design of experiments",
    "section": "DoE.base",
    "text": "DoE.base\nDoE.base provides utility functions for the special class design and as seen in Figure @ref(fig:doe-network), DoE.base is used by four other DoE packages that is maintained also by Prof. Dr. Ulrike Grömping.\nDoE.base contains functions to generate factorial designs easily.\n\nlibrary(DoE.base)\n\nLoading required package: grid\n\n\nLoading required package: conf.design\n\n\nRegistered S3 method overwritten by 'DoE.base':\n  method           from       \n  factorize.factor conf.design\n\n\n\nAttaching package: 'DoE.base'\n\n\nThe following objects are masked from 'package:stats':\n\n    aov, lm\n\n\nThe following object is masked from 'package:graphics':\n\n    plot.design\n\n\nThe following object is masked from 'package:base':\n\n    lengths\n\nfac.design(nlevels = c(2, 2, 3, 3, 6), \n           blocks = 6)\n\ncreating full factorial with 216 runs ...\n\n\n   run.no run.no.std.rp Blocks A B C D E\n1       1        29.1.5      1 1 1 2 3 1\n2       2       89.1.15      1 1 1 2 2 3\n3       3      180.1.30      1 2 2 3 3 5\n4       4         4.1.2      1 2 2 1 1 1\n5       5       84.1.14      1 2 2 3 1 3\n6       6      160.1.28      1 2 2 1 2 5\n7       7      118.1.19      1 2 1 3 1 4\n8       8      186.1.31      1 2 1 2 1 6\n9       9       97.1.17      1 1 1 1 3 3\n10     10       92.1.16      1 2 2 2 2 3\n11     11      214.1.35      1 2 1 3 3 6\n12     12      194.1.33      1 2 1 1 2 6\n13     13        39.1.8      1 1 2 1 1 2\n14     14         1.1.1      1 1 1 1 1 1\n15     15      119.1.20      1 1 2 3 1 4\n16     16      127.1.22      1 1 2 2 2 4\n17     17      134.1.23      1 2 1 1 3 4\n18     18        58.1.9      1 2 1 3 2 2\n19     19      135.1.24      1 1 2 1 3 4\n20     20      149.1.25      1 1 1 2 1 5\n21     21       59.1.10      1 1 2 3 2 2\n22     22        38.1.7      1 2 1 1 1 2\n23     23       67.1.12      1 1 2 2 3 2\n24     24      195.1.34      1 1 2 1 2 6\n25     25        32.1.6      1 2 2 2 3 1\n26     26       66.1.11      1 2 1 2 3 2\n27     27      152.1.26      1 2 2 2 1 5\n28     28        21.1.3      1 1 1 3 2 1\n29     29      157.1.27      1 1 1 1 2 5\n30     30      215.1.36      1 1 2 3 3 6\n31     31      100.1.18      1 2 2 1 3 3\n32     32      187.1.32      1 1 2 2 1 6\n33     33      177.1.29      1 1 1 3 3 5\n34     34      126.1.21      1 2 1 2 2 4\n35     35       81.1.13      1 1 1 3 1 3\n36     36        24.1.4      1 2 2 3 2 1\n   run.no run.no.std.rp Blocks A B C D E\n37     37        16.2.4      2 2 2 1 2 1\n38     38      169.2.29      2 1 1 1 3 5\n39     39        43.2.8      2 1 2 2 1 2\n40     40      199.2.34      2 1 2 2 2 6\n41     41      104.2.18      2 2 2 2 3 3\n42     42      206.2.35      2 2 1 1 3 6\n43     43      131.2.22      2 1 2 3 2 4\n44     44      138.2.23      2 2 1 2 3 4\n45     45      172.2.30      2 2 2 1 3 5\n46     46      110.2.19      2 2 1 1 1 4\n47     47      161.2.27      2 1 1 2 2 5\n48     48         5.2.1      2 1 1 2 1 1\n49     49        42.2.7      2 2 1 2 1 2\n50     50       73.2.13      2 1 1 1 1 3\n51     51      191.2.32      2 1 2 3 1 6\n52     52       93.2.15      2 1 1 3 2 3\n53     53      156.2.26      2 2 2 3 1 5\n54     54       96.2.16      2 2 2 3 2 3\n55     55       51.2.10      2 1 2 1 2 2\n56     56      101.2.17      2 1 1 2 3 3\n57     57        13.2.3      2 1 1 1 2 1\n58     58      111.2.20      2 1 2 1 1 4\n59     59      130.2.21      2 2 1 3 2 4\n60     60       76.2.14      2 2 2 1 1 3\n61     61      198.2.33      2 2 1 2 2 6\n62     62      190.2.31      2 2 1 3 1 6\n63     63        33.2.5      2 1 1 3 3 1\n64     64      153.2.25      2 1 1 3 1 5\n65     65      164.2.28      2 2 2 2 2 5\n66     66        50.2.9      2 2 1 1 2 2\n67     67      207.2.36      2 1 2 1 3 6\n68     68       71.2.12      2 1 2 3 3 2\n69     69        36.2.6      2 2 2 3 3 1\n70     70         8.2.2      2 2 2 2 1 1\n71     71       70.2.11      2 2 1 3 3 2\n72     72      139.2.24      2 1 2 2 3 4\n    run.no run.no.std.rp Blocks A B C D E\n73      73       85.3.15      3 1 1 1 2 3\n74      74      105.3.17      3 1 1 3 3 3\n75      75        17.3.3      3 1 1 2 2 1\n76      76      211.3.36      3 1 2 2 3 6\n77      77      114.3.19      3 2 1 2 1 4\n78      78        47.3.8      3 1 2 3 1 2\n79      79       55.3.10      3 1 2 2 2 2\n80      80      182.3.31      3 2 1 1 1 6\n81      81      168.3.28      3 2 2 3 2 5\n82      82      165.3.27      3 1 1 3 2 5\n83      83      142.3.23      3 2 1 3 3 4\n84      84      145.3.25      3 1 1 1 1 5\n85      85       62.3.11      3 2 1 1 3 2\n86      86      148.3.26      3 2 2 1 1 5\n87      87      108.3.18      3 2 2 3 3 3\n88      88        25.3.5      3 1 1 1 3 1\n89      89         9.3.1      3 1 1 3 1 1\n90      90       77.3.13      3 1 1 2 1 3\n91      91      122.3.21      3 2 1 1 2 4\n92      92        12.3.2      3 2 2 3 1 1\n93      93        46.3.7      3 2 1 3 1 2\n94      94       88.3.16      3 2 2 1 2 3\n95      95        20.3.4      3 2 2 2 2 1\n96      96        54.3.9      3 2 1 2 2 2\n97      97      203.3.34      3 1 2 3 2 6\n98      98       80.3.14      3 2 2 2 1 3\n99      99      123.3.22      3 1 2 1 2 4\n100    100      173.3.29      3 1 1 2 3 5\n101    101        28.3.6      3 2 2 1 3 1\n102    102      176.3.30      3 2 2 2 3 5\n103    103      202.3.33      3 2 1 3 2 6\n104    104      115.3.20      3 1 2 2 1 4\n105    105      210.3.35      3 2 1 2 3 6\n106    106      183.3.32      3 1 2 1 1 6\n107    107       63.3.12      3 1 2 1 3 2\n108    108      143.3.24      3 1 2 3 3 4\n    run.no run.no.std.rp Blocks A B C D E\n109    109      179.4.30      4 1 2 3 3 5\n110    110      151.4.26      4 1 2 2 1 5\n111    111       60.4.10      4 2 2 3 2 2\n112    112        31.4.6      4 1 2 2 3 1\n113    113         3.4.2      4 1 2 1 1 1\n114    114        22.4.3      4 2 1 3 2 1\n115    115       99.4.18      4 1 2 1 3 3\n116    116        30.4.5      4 2 1 2 3 1\n117    117       68.4.12      4 2 2 2 3 2\n118    118      196.4.34      4 2 2 1 2 6\n119    119       90.4.15      4 2 1 2 2 3\n120    120        57.4.9      4 1 1 3 2 2\n121    121      158.4.27      4 2 1 1 2 5\n122    122      193.4.33      4 1 1 1 2 6\n123    123      136.4.24      4 2 2 1 3 4\n124    124       82.4.13      4 2 1 3 1 3\n125    125       65.4.11      4 1 1 2 3 2\n126    126        37.4.7      4 1 1 1 1 2\n127    127      120.4.20      4 2 2 3 1 4\n128    128      178.4.29      4 2 1 3 3 5\n129    129      128.4.22      4 2 2 2 2 4\n130    130      188.4.32      4 2 2 2 1 6\n131    131         2.4.1      4 2 1 1 1 1\n132    132       91.4.16      4 1 2 2 2 3\n133    133      185.4.31      4 1 1 2 1 6\n134    134      159.4.28      4 1 2 1 2 5\n135    135       98.4.17      4 2 1 1 3 3\n136    136        40.4.8      4 2 2 1 1 2\n137    137      150.4.25      4 2 1 2 1 5\n138    138      125.4.21      4 1 1 2 2 4\n139    139       83.4.14      4 1 2 3 1 3\n140    140      133.4.23      4 1 1 1 3 4\n141    141        23.4.4      4 1 2 3 2 1\n142    142      117.4.19      4 1 1 3 1 4\n143    143      216.4.36      4 2 2 3 3 6\n144    144      213.4.35      4 1 1 3 3 6\n    run.no run.no.std.rp Blocks A B C D E\n145    145      171.5.30      5 1 2 1 3 5\n146    146      102.5.17      5 2 1 2 3 3\n147    147      162.5.27      5 2 1 2 2 5\n148    148      112.5.20      5 2 2 1 1 4\n149    149      154.5.25      5 2 1 3 1 5\n150    150       74.5.13      5 2 1 1 1 3\n151    151      163.5.28      5 1 2 2 2 5\n152    152        15.5.4      5 1 2 1 2 1\n153    153       72.5.12      5 2 2 3 3 2\n154    154       95.5.16      5 1 2 3 2 3\n155    155      205.5.35      5 1 1 1 3 6\n156    156        35.5.6      5 1 2 3 3 1\n157    157         7.5.2      5 1 2 2 1 1\n158    158      129.5.21      5 1 1 3 2 4\n159    159         6.5.1      5 2 1 2 1 1\n160    160       75.5.14      5 1 2 1 1 3\n161    161      208.5.36      5 2 2 1 3 6\n162    162        14.5.3      5 2 1 1 2 1\n163    163       94.5.15      5 2 1 3 2 3\n164    164      132.5.22      5 2 2 3 2 4\n165    165        34.5.5      5 2 1 3 3 1\n166    166       69.5.11      5 1 1 3 3 2\n167    167      170.5.29      5 2 1 1 3 5\n168    168      137.5.23      5 1 1 2 3 4\n169    169       52.5.10      5 2 2 1 2 2\n170    170      155.5.26      5 1 2 3 1 5\n171    171        49.5.9      5 1 1 1 2 2\n172    172      200.5.34      5 2 2 2 2 6\n173    173        41.5.7      5 1 1 2 1 2\n174    174      192.5.32      5 2 2 3 1 6\n175    175        44.5.8      5 2 2 2 1 2\n176    176      140.5.24      5 2 2 2 3 4\n177    177      197.5.33      5 1 1 2 2 6\n178    178      109.5.19      5 1 1 1 1 4\n179    179      103.5.18      5 1 2 2 3 3\n180    180      189.5.31      5 1 1 3 1 6\n    run.no run.no.std.rp Blocks A B C D E\n181    181      106.6.17      6 2 1 3 3 3\n182    182      146.6.25      6 2 1 1 1 5\n183    183       79.6.14      6 1 2 2 1 3\n184    184        53.6.9      6 1 1 2 2 2\n185    185      209.6.35      6 1 1 2 3 6\n186    186       64.6.12      6 2 2 1 3 2\n187    187      166.6.27      6 2 1 3 2 5\n188    188        19.6.4      6 1 2 2 2 1\n189    189      204.6.34      6 2 2 3 2 6\n190    190        26.6.5      6 2 1 1 3 1\n191    191       78.6.13      6 2 1 2 1 3\n192    192       56.6.10      6 2 2 2 2 2\n193    193      181.6.31      6 1 1 1 1 6\n194    194      174.6.29      6 2 1 2 3 5\n195    195       87.6.16      6 1 2 1 2 3\n196    196        10.6.1      6 2 1 3 1 1\n197    197      212.6.36      6 2 2 2 3 6\n198    198      147.6.26      6 1 2 1 1 5\n199    199      107.6.18      6 1 2 3 3 3\n200    200        48.6.8      6 2 2 3 1 2\n201    201      116.6.20      6 2 2 2 1 4\n202    202       86.6.15      6 2 1 1 2 3\n203    203      184.6.32      6 2 2 1 1 6\n204    204        27.6.6      6 1 2 1 3 1\n205    205      124.6.22      6 2 2 1 2 4\n206    206      141.6.23      6 1 1 3 3 4\n207    207      201.6.33      6 1 1 3 2 6\n208    208        18.6.3      6 2 1 2 2 1\n209    209        45.6.7      6 1 1 3 1 2\n210    210      113.6.19      6 1 1 2 1 4\n211    211      167.6.28      6 1 2 3 2 5\n212    212      121.6.21      6 1 1 1 2 4\n213    213      144.6.24      6 2 2 3 3 4\n214    214       61.6.11      6 1 1 1 3 2\n215    215      175.6.30      6 1 2 2 3 5\n216    216        11.6.2      6 1 2 3 1 1\nclass=design, type= full factorial.blocked \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\n\nIt also contains functions to create orthogonal array designs.\n\ndes <- oa.design(nlevels = c(rep(2, 8), 8))\ndes\n\n   A B C D E F G H J\n1  1 2 1 2 2 1 2 1 6\n2  2 1 2 1 2 1 2 1 2\n3  2 1 1 2 2 1 1 2 4\n4  2 2 1 1 2 2 1 1 3\n5  1 1 1 1 2 2 2 2 5\n6  1 1 2 2 2 2 1 1 7\n7  1 2 1 2 1 2 1 2 2\n8  1 1 1 1 1 1 1 1 1\n9  1 2 2 1 2 1 1 2 8\n10 1 1 2 2 1 1 2 2 3\n11 2 1 2 1 1 2 1 2 6\n12 2 1 1 2 1 2 2 1 8\n13 2 2 2 2 1 1 1 1 5\n14 2 2 1 1 1 1 2 2 7\n15 1 2 2 1 1 2 2 1 4\n16 2 2 2 2 2 2 2 2 1\nclass=design, type= oa \n\n\nIf you need to further randomise within a specified block, you can do this using rerandomize.design.\n\nrerandomize.design(des, block = \"J\")\n\n  run.no run.no.std.rp J A B C D E F G H\n1      1         4.7.1 7 1 1 2 2 2 2 1 1\n2      2        13.7.2 7 2 2 1 1 1 1 2 2\n  run.no run.no.std.rp J A B C D E F G H\n3      3         7.4.1 4 1 2 2 1 1 2 2 1\n4      4        10.4.2 4 2 1 1 2 2 1 1 2\n  run.no run.no.std.rp J A B C D E F G H\n5      5        12.2.2 2 2 1 2 1 2 1 2 1\n6      6         5.2.1 2 1 2 1 2 1 2 1 2\n  run.no run.no.std.rp J A B C D E F G H\n7      7        11.6.2 6 2 1 2 1 1 2 1 2\n8      8         6.6.1 6 1 2 1 2 2 1 2 1\n   run.no run.no.std.rp J A B C D E F G H\n9       9         9.8.2 8 2 1 1 2 1 2 2 1\n10     10         8.8.1 8 1 2 2 1 2 1 1 2\n   run.no run.no.std.rp J A B C D E F G H\n11     11         3.3.1 3 1 1 2 2 1 1 2 2\n12     12        14.3.2 3 2 2 1 1 2 2 1 1\n   run.no run.no.std.rp J A B C D E F G H\n13     13        16.1.2 1 2 2 2 2 2 2 2 2\n14     14         1.1.1 1 1 1 1 1 1 1 1 1\n   run.no run.no.std.rp J A B C D E F G H\n15     15         2.5.1 5 1 1 1 1 2 2 2 2\n16     16        15.5.2 5 2 2 2 2 1 1 1 1\nclass=design, type= oa.blocked \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\n\nSo those were the top 5 DoE packages. The API of the packages are quite distinct. The object that it outputs can vary from a matrix to a list. DoE might be a dull area for many but it’s quite important for the downstream analysis. Perhaps if many of us talk more about it, it may help invigorate the area!"
  },
  {
    "objectID": "blog/2022-03-06-the-war/the-war.html",
    "href": "blog/2022-03-06-the-war/the-war.html",
    "title": "War",
    "section": "",
    "text": "When I lived in Greece, I was a young child with little comprehension of what’s going on. In the course of my life, this event had little effect on me but just a distant hazy memory. Today as a fully grown adult, I’m sure I would have been terrified being in the midst of uncertainty. War affects many citizens, including the creator of Leaflet as pointed out by Hiroaki Yutani-san. If ever you need a time to remind yourself how lucky you are to have shelter, food and water, now is probably the time.\nLiving in Melbourne, so far away from Ukraine, life is going on like normal, bickering over first world problems. What good is in a war? If you are in a good position to, please consider helping those in need. I donated US$500 to Ukraine Red Cross Society but I found later that there was the Ukraine Crisis Appeal in the Australian Red Cross."
  },
  {
    "objectID": "blog/2022-02-24-simulation-proof-of-concept/simulation-proof-of-concept.html",
    "href": "blog/2022-02-24-simulation-proof-of-concept/simulation-proof-of-concept.html",
    "title": "simulate: proof of concept R-package",
    "section": "",
    "text": "library(tidyverse)\nlibrary(palmerpenguins)\nlibrary(simulate)\ntheme_set(theme_bw())\nset.seed(2022-02-24)\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nLet’s now say you want to simulate a new response called weight which you assume is normally distributed where the mean is a function of species and variance is 10. We want to specify the mean separately by species such that Adelie, Chinstrap and Gentoo are 130kg, 200kg and 250kg respectively (These numbers are totally made up!!! And probably way heavey for a penguin?).\n\nsim1 <- penguins %>% \n  simulate(weight = sim_normal(~species, 10) %>% \n             params(\"mean\", species = c(\"Adelie\"    = 130,\n                                        \"Chinstrap\" = 200,\n                                        \"Gentoo\"    = 250)))\n\nLet’s visualise to see if the weight was simulated as expected:\n\nggplot(sim1, aes(species, weight)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1)\n\n\n\n\nYou can make other parameters, like the standard deviation, as a function of species as well.\n\nsim2 <- penguins %>% \n  simulate(weight = sim_normal(~species, ~species) %>% \n             params(\"mean\", species = c(\"Adelie\"    = 130,\n                                        \"Chinstrap\" = 200,\n                                        \"Gentoo\"    = 250)) %>% \n             params(\"sd\", species = c(\"Adelie\"    = 10,\n                                      \"Chinstrap\" = 40,\n                                      \"Gentoo\"    = 100) ))\n\nAnd here’s the visualisation:\n\nggplot(sim2, aes(species, weight)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1)\n\n\n\n\nOkay one more before I call it a night. sim_form is a fixed function structure here and I’m simulating weight as a mixture distribution – the weight is either based on the sex or the species (perhaps simulating a situation where some genes aren’t expressed more based on sex sometimes, and sometimes more based on species?? These simulations are just made up.)\n\nsim3 <- penguins %>% \n  simulate(weight = sim_form(~p[1] * sex + p[2] * species) %>% \n             params(species = c(\"Adelie\"    = 130,\n                                \"Chinstrap\" = 200,\n                                \"Gentoo\"    = 250),\n                    # it can be unnamed as well\n                    sex = c(40, 200),\n                    # or specify a distribution\n                    p = sim_multinominal(1, c(0.2, 0.8))))\n\nNote: the plot below is jittered so you can see all the points.\n\nggplot(sim3, aes(species, weight)) +\n  geom_jitter() + \n  facet_grid(sex ~ species)\n\n\n\n\nThe multivariate part is not shown but a keen user may find how this is envisioned at the moment if you dig deep into the source code… Hint: there is a .cor function to feed in a correlation matrix."
  },
  {
    "objectID": "blog/2022-06-30-academic-ranks/academic-ranks.html",
    "href": "blog/2022-06-30-academic-ranks/academic-ranks.html",
    "title": "Academic ranks",
    "section": "",
    "text": "Information taken from these wikipedia articles: Academic ranks in Australian and New Zealand and Academic ranks in UK."
  },
  {
    "objectID": "blog/2022-10-15-affective-colors/index.html",
    "href": "blog/2022-10-15-affective-colors/index.html",
    "title": "Affective colors in data visualisation",
    "section": "",
    "text": "affect\nfrequency plot\n\n\n\n\ncalm\n\n\n\ndisturbing\n\n\n\nexciting\n\n\n\nnegative\n\n\n\nplayful\n\n\n\npositive\n\n\n\nserious\n\n\n\ntrustworthy\n\n\n\n\nThe paper is quite interesting but I actually couldn’t find the list of colors for each affect! So below is my simple analysis where I read in the image of the frequency plot, convert the colors to hex colors and remove white background to get the frequency of the colors. I plot then the top 10 colors for each affect.\n\nlibrary(tidyverse)\nlibrary(png)\n# reads it as an 3d array where first two dimensions are\n# the location on the image \n# last dimension contains 4 columns which are r, g, b, alpha\nimgs <- list(calm = readPNG(\"calm.png\"),\n             disturbing = readPNG(\"disturbing.png\"),\n             exciting = readPNG(\"exciting.png\"),\n             negative = readPNG(\"negative.png\"),\n             playful = readPNG(\"playful.png\"),\n             positive = readPNG(\"positive.png\"),\n             serious = readPNG(\"serious.png\"),\n             trustworthy = readPNG(\"trustworthy.png\"))\n\ndims <- map(imgs, dim)\n# convert array to a matrix\nmats <- imap(imgs, ~matrix(.x, prod(dims[[.y]][1:2]), dims[[.y]][3]))\n\n# get the frequency of colors as a data frame\ncolors <- imap_dfr(mats, ~{\n                  res <- rgb(.x[, 1], .x[, 2], .x[, 3], .x[, 4])\n                  data.frame(color = res[res!=\"#FFFFFFFF\"]) \n                }, .id = \"affect\") %>% \n  count(affect, color) %>% \n  group_by(affect) %>% \n  mutate(prop = n / sum(n))\n\n\nwalk(names(imgs), ~{\n  g <- colors %>% \n    filter(affect == .x) %>% \n    slice_max(prop, n = 10) %>% \n    mutate(color = fct_reorder(color, prop)) %>% \n    ggplot(aes(prop, color)) +\n      geom_col(aes(fill = I(color)), color = \"black\") + \n      labs(title = .x, x = \"Proportion\", y = \"\") +\n      scale_x_continuous(expand = c(0.01, 0)) +\n      theme(text = element_text(size = 14),\n            panel.background = element_blank(),\n            panel.grid.major.x = element_line(color = \"grey\", linetype = \"dashed\"),\n            axis.ticks.length = unit(0, \"mm\"))\n  print(g)\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nBartram, Lyn, Abhisekh Patra, and Maureen Stone. 2017. “Affective Color in Visualization.” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 1364–74. CHI ’17. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3025453.3026041."
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "",
    "text": "This blog post attempts to describe the experimental design in Williams et al. (2021) for sensory discrimination test on vegemite using the edibble R package. Detailed descriptions are provided in Williams et al. (2021) and I only provide an abridged version in this blog, except where quoted.\nFirst, I load the packages needed. The edibble package is currently only available on GitHub at https://github.com/emitanaka/edibble with plans to submit to CRAN in the next couple of months.\nThere are three types of sensory discrimination tests that are used by sensory scientists Drs Ciarán Forde and Patrick O’Riordan in an experiment to see if a story about an alternative to vegemite could sharpen the taste buds and improve the discriminative abilities of Australian consumers. The three sensory discrimination tests are as described below in Williams et al. (2021):\nThese test are abbreviated as T, PP, and M, respectively. The experimental structure is briefly summarised below:\nThe following is the experimental design description in Williams et al. (2021):"
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#test-order",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#test-order",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "Test order",
    "text": "Test order\n\nOn each day half of the consumers took the sequence of monadic tests first and the other half after either the paired preference or triangle tests.\n\nRecall:\n\nexperiment is conducted over 4 days\nlogistics allow only 42 consumers per day\ncover story (or lack there of) is shown based on the day\n\nAt first I couldn’t tell whether the cover story and the sensory tests (T and PP) were randomised or in systematic order, but in my communication with Emlyn Williams, he let me know it was randomised.\n\nset.seed(1)\ndes1 <- design(\"sensory evalution\") %>% \n  set_units(day = 4,\n            consumer = nested_in(day, 42)) %>% \n  set_trts(cover_story = c(\"yes\", \"no\"),\n           test = c(\"T,M\", \"PP,M\"),\n           test_first = c(\"T/PP\", \"M\")) %>% \n  allot_table(test:cover_story ~ day,\n                    test_first ~ consumer)\n\n\ndes1\n\n# sensory evalution \n# An edibble: 168 x 5\n         day    consumer cover_story     test test_first\n   <unit(4)> <unit(168)>    <trt(2)> <trt(2)>   <trt(2)>\n 1      day1  consumer1          yes      T,M       T/PP\n 2      day1  consumer2          yes      T,M       M   \n 3      day1  consumer3          yes      T,M       T/PP\n 4      day1  consumer4          yes      T,M       T/PP\n 5      day1  consumer5          yes      T,M       T/PP\n 6      day1  consumer6          yes      T,M       M   \n 7      day1  consumer7          yes      T,M       T/PP\n 8      day1  consumer8          yes      T,M       M   \n 9      day1  consumer9          yes      T,M       M   \n10      day1  consumer10         yes      T,M       M   \n# … with 158 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nYou can check the allocation of the cover story and test by nesting it by day:\n\ndes1 %>% \n  nest_by(day, cover_story, test)\n\n# A tibble: 4 × 4\n# Rowwise:  day, cover_story, test\n        day cover_story     test               data\n  <unit(4)>    <trt(2)> <trt(2)> <list<tibble[,2]>>\n1      day1         yes     T,M            [42 × 2]\n2      day2         no      PP,M           [42 × 2]\n3      day3         yes     PP,M           [42 × 2]\n4      day4         no      T,M            [42 × 2]"
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#triangle-test",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#triangle-test",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "Triangle test",
    "text": "Triangle test\n\nFor the triangle test there are six possible triplets involving the two products (labelled N and S for normal and spiked vegemite respectively), namely: NNS, SNN, NSN, SSN, NSS and SNS. Two of these triplets were presented in sequence to each consumer and so an optimal row–column design was constructed for six treatments (triplets) in two rows (order of presentation) and 42 columns (consumers)… if the consumer received a triplet with two of the normal vegemite then the second triplet would contain two of the spiked vegemite. Separate randomisations of the design were used for 2 days.\n\nRecall:\n\neach consumer taste no more than 12 samples of vegemite\nlogistics allow only 42 consumers per day\n\nAs every consumer also does the monadic test which uses 6 samples, only 6 samples remain for the triangle test. The product lineups took me a while to figure it out – the part that tripped me up was that the two lineups (out of NNS, SNN, NSN, SSN, NSS and SNS) that was presented to the consumer sequentially had to have the major product swapped, so you can’t choose something like NNS and NSN because both lineups have the major product as N. This precludes from just two random selections from NNS, SNN, NSN, SSN, NSS and SNS, and requires a conditional randomisation.\nI decided to think of this as a two step process:\n\nchoose the main product, and\nchoose out of the sequences XXO, XOX and OXX where X denotes the major product.\n\nSince the product lineup is nested within the consumer, the major product allocation in edibble below automatically treats consumer as a block and in the assignment, it will try to ensure the major product is different in the two lineups for each consumer.\n\ndes2 <- design(\"triangle test\") %>% \n    set_units(day = c(1, 4),\n              consumer = nested_in(day, 42),\n              product_lineup = nested_in(consumer, 2)) %>% \n    set_trts(major_product = c(\"spiked\", \"normal\"),\n             sequence = c(\"XXO\", \"XOX\", \"OXX\")) %>% \n    allot_table(major_product ~ product_lineup,\n                     sequence ~ product_lineup)\n\ndes2\n\n# triangle test \n# An edibble: 168 x 5\n         day   consumer   product_lineup major_product sequence\n   <unit(2)> <unit(84)>      <unit(168)>      <trt(2)> <trt(3)>\n 1         1  consumer1 product_lineup1         normal      XOX\n 2         1  consumer1 product_lineup2         spiked      OXX\n 3         1  consumer2 product_lineup3         normal      XOX\n 4         1  consumer2 product_lineup4         spiked      OXX\n 5         1  consumer3 product_lineup5         normal      XXO\n 6         1  consumer3 product_lineup6         spiked      XOX\n 7         1  consumer4 product_lineup7         spiked      XXO\n 8         1  consumer4 product_lineup8         normal      XOX\n 9         1  consumer5 product_lineup9         normal      OXX\n10         1  consumer5 product_lineup10        spiked      XOX\n# … with 158 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nI could alternatively design the above as a row-column design.\n\ndes2alt <- design(\"triangle test\") %>% \n    set_units(day = c(1, 4),\n              consumer = nested_in(day, 42),\n              order = 2,\n              product_lineup = crossed_by(consumer, order)) %>% \n    set_trts(major_product = c(\"spiked\", \"normal\"),\n             sequence = c(\"XXO\", \"XOX\", \"OXX\")) %>% \n    allot_table(major_product ~ product_lineup,\n                     sequence ~ product_lineup)\n\ndeggust::autoplot(des2alt)"
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#paired-test",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#paired-test",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "Paired test",
    "text": "Paired test\n\nFor the paired preference test the normal vegemite in a pair can be presented either first or second. Hence an optimal row–column design was constructed for two treatments (pair order) in three rows (order of presentation) and 42 columns (consumers). Separate randomisations of the design were used for 2 days.\n\n\ndes3 <- design(\"paired test\") %>% \n    set_units(day = c(2, 3),\n              consumer = nested_in(day, 42),\n              order = 3,\n              product_lineup = crossed_by(consumer, order)) %>% \n    set_trts(product_order = c(\"SN\", \"NS\")) %>% \n    allot_table(product_order ~ product_lineup)\n\ndeggust::autoplot(des3)"
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#monadic-test",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#monadic-test",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "Monadic test",
    "text": "Monadic test\n\nFor the monadic test the six samples, three of each product (normal and spiked), were presented in a different sequential order to each consumer and so there was the chance to study the possibility of carryover effects from successive samples.\n\n\ndes4 <- design(\"monadic test\") %>% \n    set_units(day = 4,\n              consumer = nested_in(day, 42),\n              order = 6,\n              product_lineup = crossed_by(consumer, order)) %>% \n    set_trts(product = c(\"spiked\", \"normal\")) %>% \n    allot_table(product ~ product_lineup)\n\noptions(deggust.nnode_max = Inf)\ndeggust::autoplot(des4)"
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#conclusion",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#conclusion",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "Conclusion",
    "text": "Conclusion\nSo you might be wondering if Australians can indeed distinguish the true taste of vegemite? Well this blog post is not about the analysis but the experimental design. A short analysis is provided, however, in Williams et al. (2021) … and the answer is yes Australians knows their vegemite 😉"
  },
  {
    "objectID": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#acknowldegement",
    "href": "blog/2022-03-27-sensory-discrimination-tests/sensory-discrimination-tests.html#acknowldegement",
    "title": "edibble experimental design with sensory discrimination tests",
    "section": "Acknowldegement",
    "text": "Acknowldegement\nI want to thank Emyln for being so prompt in answering my questions about this experiment and providing the data (which I didn’t end up using in this blog post), that was mistakenly missing in the initial publication but available now on the website."
  },
  {
    "objectID": "blog/hexsticker/hexsticker.html",
    "href": "blog/hexsticker/hexsticker.html",
    "title": "Making a Hexagon Sticker",
    "section": "",
    "text": "Making hexagon stickers have become popular for R-packages with the range of packages associated with RStudio, such as ggplot2, knitr, devtools and so on, having its own hex stickers.\nThis trend even spanned a R-package hexSticker that can be found here."
  },
  {
    "objectID": "blog/hexsticker/hexsticker.html#powerpoint-template-for-hex-stickers",
    "href": "blog/hexsticker/hexsticker.html#powerpoint-template-for-hex-stickers",
    "title": "Making a Hexagon Sticker",
    "section": "Powerpoint template for hex stickers",
    "text": "Powerpoint template for hex stickers\nFor the sticker that I made for my R-package shinycustomloader, I found it easier, partly due to its long name, to use powerpoint to manipulate the image and create a semi-circular text. It took longer than what I had hoped to get the hexagon shape right. You may like to save your own time by downloading my powerpoint template here as a base to make your own.\nThe dimensions were set, as it is in hexSticker, so that you can print it according to http://hexb.in/sticker.html."
  },
  {
    "objectID": "blog/hexsticker/hexsticker.html#using-copyright-images-in-hex-stickers",
    "href": "blog/hexsticker/hexsticker.html#using-copyright-images-in-hex-stickers",
    "title": "Making a Hexagon Sticker",
    "section": "Using copyright images in hex stickers",
    "text": "Using copyright images in hex stickers\nIt’s worth noting about copyright of images since you may like to use images in your hex sticker. If you created the image on your own then the copyright in general will rest with you and there is no problem. If you borrow images from others, you may need to provide attribution depending on their license permission.\nIn hex stickers, you don’t really have a room to add citations so you may like to use those that require no attribution. For free ones, you can find these using sites such as flickr under Public Domain works (CC0).\nIt is a bit painful to consider copyright issues but it is important to give due credit, acknowledgement, attribution etc to the creator of the work. I’ve gone to great lengths at times to search for CC0 images or have paid for work. Afterall, creative work is valuable and should be properly rewarded.\nUPDATE 22/06 My sticker arrived! They are pretty good quality! I also got 16 which is more than the 10 sample they said on the website \n\nThese are from sticker mule. If you sign up with referral code here, both you and I will get some credit. You are, of course, welcomed to just go directly to the site to make the purchase.\n\nUPDATE 20/06/2021 When ordering an R-package hex sticker from sticker mule, I choose Stickers > Die cut stickers > Custom dimension of 1.73” x 1.99”."
  },
  {
    "objectID": "blog/travel2019/travel2019.html",
    "href": "blog/travel2019/travel2019.html",
    "title": "My Travel Schedule 2019: Building an interactive visualisation as twitter card",
    "section": "",
    "text": "Hovering over the above graph will show you more details. This year I have a fair bit of travel scheduled including:\n\nEco Sta 2019 at Taichung, Taiwan,\nISI WSC 2019 at Kuala Lumpur, Malaysia,\nYSC 2019 at Canberra, Australia, and\nBiometrics by the Botanic Garden 2019 at Adelaide, Australia.\n\nIf you happen to be going to the same conference as myself, do get in touch and maybe you can pay for my taxi? :) (I forgot to put it in my budget …)\nThe code to make the above graph is shown below. This post benefit largely from this post here to turn plotly output into interactive twitter card.\n\nlibrary(tidyverse)\nlibrary(tsibble)\nlibrary(googlesheets4)\nlibrary(highcharter)\nlibrary(widgetframe)\n\n# get the data\ndate_range <- tibble(\n  Dates = as.Date(c(\"06/03/2019\", \"12/31/2019\"), format = \"%m/%d/%Y\"),\n  Location = \"Sydney, Australia\"\n) # the start to end for schedule show\ntravel_df <- read_sheet(\"1T7aH5PzQghU0htnqOjzzEyfe0qdWs_L-1Ybu9PX-rYY\") %>%\n  mutate(\n    Start = as.Date(Start, format = \"%m/%d/%Y\"),\n    End = as.Date(End, format = \"%m/%d/%Y\")\n  ) %>%\n  pivot_longer(Start:End, names_to = \"Time\", values_to = \"Dates\") %>%\n  as_tsibble(key = Event, index = Dates) %>%\n  fill_gaps(Time = \"Between\") %>%\n  group_by(Event) %>%\n  fill(FullEvent, URL, Location, What, .direction = \"down\") %>%\n  ungroup() %>% # this part feels clumsy.. probably better way to do this\n  bind_rows(date_range) %>%\n  as_tibble() %>%\n  mutate(Key = \"All\") %>%\n  as_tsibble(key = Key, index = Dates) %>%\n  fill_gaps(Location = \"Sydney, Australia\", Event = \"\", What = \"\", FullEvent = \"\") %>%\n  mutate(\n    Day = substring(weekdays(Dates), 1, 3),\n    Week = lubridate::isoweek(Dates)\n  ) %>%\n  filter(Week != 1)\n\n\nfntltp <- JS(\"function(){\n              return '<b style=\\\"color:#DC5084\\\">' + this.point.event + '</b><br><span style=\\\"font-size:0.7em\\\">' +  this.series.yAxis.categories[this.point.y] + ', ' +\n             this.point.date + '</span><br><span style=\\\"font-size:0.7em\\\">' + this.point.name + '</span><br><span style=\\\"font-size:0.7em;color:#FFFFCC\\\">' + this.point.what + '</span><br>'+ this.point.loc;\n             }\")\n\nhcout <- hchart(travel_df, \"heatmap\", hcaes(\n  x = factor(Week),\n  y = factor(Day, levels = c(\"Sun\", \"Sat\", \"Fri\", \"Thu\", \"Wed\", \"Tue\", \"Mon\")),\n  group = Location,\n  loc = Location,\n  event = Event,\n  what = What,\n  name = FullEvent,\n  date = Dates\n),\nstyle = list(fontSize = \"2em\", fontFamily = \"Helvetica\")\n) %>%\n  hc_tooltip(formatter = fntltp) %>%\n  # hc_tooltip(crosshairs=TRUE, pointFormat = \"y: {point.y}<br>x: {point.x}\") %>%\n  hc_title(text = \"My 2019 Travel Schedule\", style = list(fontWeight = \"bold\")) %>%\n  hc_subtitle(text = \"Hover over the tile to see more information\") %>%\n  hc_size(height = 225) %>%\n  hc_legend(enabled = FALSE) %>%\n  hc_yAxis(title = \"\") %>%\n  hc_xAxis(\n    title = \"\", categories = c(\"Jun\", \"\", \"\", \"\", \"Jul\", \"\", \"\", \"\", \"Aug\", \"\", \"\", \"\", \"Sep\", \"\", \"\", \"\", \"\", \"Oct\", \"\", \"\", \"\", \"Nov\", \"\", \"\", \"\", \"Dec\", \"\", \"\", \"\"),\n    endOnTick = FALSE\n  ) %>%\n  hc_add_theme(hc_theme_538()) %>%\n  hc_plotOptions(heatmap = list(borderColor = \"black\", borderWidth = 1))\n\nframeWidget(hcout)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Scholar\n  \n  \n    \n     Monash\nI’m a Senior Lecturer (in the Australian system) in Statistics at the Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia and part of the NUMBATs group.\nMy research interests are:\nI speak English, Japanese (conversational) and R (base + tidyverse) fluently. I’ve lived in Australia almost all of my life (+-10 years standard deviation) and my university major was mathematics and statistics. My PhD, obtained at the School of Mathematics and Statistics, University of Sydney in 2015, is in statistical bioinformatics with most of my code written in Python and Bash (both of which I am rusty now). I also like to dabble on front-end web development (HTML/CSS/JS).\nI am a big advocate of open science. My code are mostly available on my GitHub profile where I also host a number of R packages that I have developed."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\n\n\n\n\n\n\nstatsgen\n\n\n\nemitanaka@fosstodon.org\n\n\n\nemitanaka\n\n\n\nemi.tanaka@monash.edu\n\n\n\nMonash University29 Ancora Imparo WayEducation Building 6 Room 341Clayton campus, VIC 3800Australia\n\n\n\n\n\nPlease note that I will not respond to emails if I cannot identify who you are (i.e. not anonymous and has affiliation)."
  },
  {
    "objectID": "teaching/index.html#teaching",
    "href": "teaching/index.html#teaching",
    "title": "Teaching",
    "section": "Teaching",
    "text": "Teaching\nAt Monash University, I teach or develop:\n\nETC5512 Wild Caught Data (25%)\nETC5523 Communicating with Data (100%)\nIntroduction to R materials\n\nIn the past I have taught:\n\nETC5521 Exploratory Data Analysis (50%) at Monash University,\nSTAT5002 Introduction to Statistics (50%) at The University of Sydney,\nSTAT3012 Applied Linear Models (75%) at The University of Sydney,\nSTAT906 Experimental Design (100%) at the University of Wollongong,\n\nand tutored various mathematics and statistics courses at The Univeristy of Sydney including lecturing for MATH1013 Mathematical Modelling (50%)."
  },
  {
    "objectID": "teaching/index.html#workshop",
    "href": "teaching/index.html#workshop",
    "title": "Teaching",
    "section": "Workshop",
    "text": "Workshop\n\n\nData Wrangling with R  Last hosted by the Statistical Society of Australia NSW Branch at 1/12/20\n\n\nData Visualisation with R  Last hosted by the Statistical Society of Australia VIC Branch at 11/11/20\n\n\nTidyverse and R Markdown Workshop  Last hosted by the International Biometrics Society Australasia Region at 1/12/19\n\n\nR Package & R Markdown Workshop  Last hosted by the Statistical Society of Australia VIC Branch at 19/11/19\n\n\nStatistical Methods for Omics Assisted Breeding  Last hosted by the Univeristy of Tokyo at 12/11/18\n\n\n\nData Visualisation in R \n\n\nIntroduction to ASReml-R \n\n\nFactor Analytic Model \n\n\nSpatial Analysis of Crop Field Trials \n\n\nExperimental Design"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "emi tanaka",
    "section": "",
    "text": "Click here for the PDF version."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "News",
    "section": "",
    "text": "Tanaka (2022) Getting the most out of your experimental data with design. Biometric Bulletin 39 (4) \nTanaka & Amaliah (2022) Current state and prospects of R-packages for the design of experiments   \nStatistical Society of Australia Victorian Branch Annual Report 2021 \nTanaka, Leung & Cook (2022) Commentary on “Visualization in Operations Management Research”: Incorporating Statistical Thinking into Visualization Practices for Decision Making in Operational Management. INFORMS Journal on Data Science  \nCook, Reid & Tanaka (2021) The Foundation is Available for Thinking about Data Visualization Inferentially. Harvard Data Science Review \n\n\n\n\nYou can watch some of my latest talks from below:\n\nThe genesis of experimentation (organised by Paul Murrell as part of Ihaka Lecture Series)   \nAn anthology of experimental designs (organised by Rohan Alexander as part of Toronto Data Workshop)   \nConstructing experimental designs with the edibble R-package (organised by Fazel Almasi with funding from Intellectual Climate Fund La Trobe University)  \nVisualising experimental designs with the edibble and deggust R-packages (organised by Fazel Almasi with funding from Intellectual Climate Fund La Trobe University)  \n\n\n\n\n\nI have no advertised upcoming talks. Please feel free to invite me for a talk if I do something of your interest. You can find some of my past talks here.\n\n\n\nSabbatical approved 😊 It will be my first time in Canada so please say hi if you see me 👋 pic.twitter.com/J3Ypadoij6\n\n— Emi Tanaka (田中愛美) 💉💉💉 (@statsgen) September 28, 2022\n\n\n\n\n\nThere are currently no workshops planned.\nAll proceeds go to supporting my research activities.\n\n\n\n\n\nThanks to everyone who attended our AGM and March seminar event last week. We have the pleasure of introducing the SSA Vic Council of 2022 🎉 🎉 🎉 pic.twitter.com/nrk3nR8Ir1\n\n— SSAVictoria (@SsaVictoria) April 4, 2022\n\n\n For more information see https://statsocaus.github.io/vic/\n\n\n To join the SSA Community Slack, see here.\n\n\n\nI have now hex stickers for the edibble and deggust R packages. If you see me in-person, feel free to ask for it!\n\n\nIf you ever see me in-person, feel free to ask me for hex stickers for my R packages ☺️ pic.twitter.com/4VXdv091IM\n\n— Emi Tanaka 🌾 (@statsgen) July 2, 2021\n\n\n\n\n\nTweets by statsgen"
  }
]